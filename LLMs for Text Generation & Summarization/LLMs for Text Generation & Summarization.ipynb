{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28df5579",
   "metadata": {},
   "source": [
    "# **Leveraging LLMs for Text Generation and Summarization**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c363790",
   "metadata": {},
   "source": [
    "# **Table of Contents**\n",
    "\n",
    "- [1.1 Introduction & Motivation](#11-introduction--motivation)\n",
    "- [1.2 Transformer Architecture Fundamentals](#12-transformer-architecture-fundamentals)\n",
    "- [1.3 Categories of LLMs](#13-categories-of-llms)\n",
    "- [1.4 Basic Text Generation](#14-basic-text-generation)\n",
    "- [2.1 Extractive Summarization](#21-extractive-summarization)\n",
    "- [2.2 Abstractive Summarization & Control Parameters](#22-abstractive-summarization--control-parameters)\n",
    "- [2.3 Evaluation Metrics for Summarization](#23-evaluation-metrics-for-summarization)\n",
    "- [3.1 Complex Document Handling](#31-complex-document-handling)\n",
    "- [3.2 Multi-Document Summarization](#32-multi-document-summarization)\n",
    "- [3.3 Multimodal Summarization](#33-multimodal-summarization)\n",
    "- [Practical Exercise: Building Your Custom Summarization System](#practical-exercise-building-your-custom-summarization-system)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddceaa6",
   "metadata": {},
   "source": [
    "# **PART I - Foundations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6168f3e",
   "metadata": {},
   "source": [
    "# **1.1 Introduction & Motivation**\n",
    "### Why Summarization Matters\n",
    "- Information overload in the digital age\n",
    "- Business applications: news aggregation, document processing, research synthesis\n",
    "- Personal productivity: email summaries, meeting notes, research papers\n",
    "- Accessibility: making complex content digestible\n",
    "\n",
    "### The Evolution Story\n",
    "- Traditional approaches (pre-2020):\n",
    "  - Manual feature engineering (TF-IDF, sentence scoring)\n",
    "  - Task-specific model training\n",
    "  - Domain-specific datasets\n",
    "  - Complex evaluation pipelines\n",
    "\n",
    "- The LLM Revolution (post-2020):\n",
    "  - Simple prompt: \"Summarize this article in 3 sentences\"\n",
    "  - Often outperforms specialized models\n",
    "  - Research finding: Human evaluators prefer GPT-3 summaries 77% of the time\n",
    "\n",
    "By the end of Part I, participants should be able to:\n",
    "\n",
    "- Explain why LLMs revolutionized summarization\n",
    "- Choose appropriate LLM architectures for different tasks\n",
    "- Control basic text generation parameters\n",
    "- Engineer effective prompts for structured output\n",
    "- Generate their first LLM-based summary\n",
    "- Understand the foundation for advanced techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9504111f",
   "metadata": {},
   "source": [
    "# **1.2 Transformer Architecture Fundamentals**\n",
    "\n",
    "## The Transformer Architecture\n",
    "\n",
    "The transformer architecture revolutionized NLP when introduced in the paper \"Attention is All You Need\" (Vaswanathan et al., 2017).\n",
    "\n",
    "<!-- Transformer Architecture -->\n",
    "<div align=\"center\">\n",
    "<img src='images/transformer architecture.png' alt=\"Transformer architecture\" width=1000 height=700>\n",
    "</div>\n",
    "\n",
    "\n",
    "### Key Components:\n",
    "- **Self-Attention Mechanism**: Allows the model to weigh the importance of different words in context\n",
    "- **Multi-Head Attention**: Parallel attention mechanisms capturing different relationships\n",
    "- **Positional Encoding**: Helps the model understand word order\n",
    "- **Feed-Forward Networks**: Process the representations from attention layers\n",
    "- **Layer Normalization**: Stabilizes training\n",
    "\n",
    "\n",
    "### Why Transformers Excel at Text Tasks,\n",
    "1. **Parallel Processing**: Unlike RNNs, can process entire sequences simultaneously\n",
    "2. **Long-Range Dependencies**: Attention mechanism captures distant relationships\n",
    "3. **Context Awareness**: Each token attends to all other tokens in the sequence\n",
    "4. **Scalability**: Architecture scales well with data and compute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b85d1e",
   "metadata": {},
   "source": [
    "## **1.3 Categories of LLMs**\n",
    "\n",
    "LLMs come in different architectural variants, each with strengths for different tasks:\n",
    "\n",
    "### 1. Decoder-Only Models (Autoregressive)\n",
    "- Examples: GPT series, LLaMA, Claude\n",
    "**When to use:**\n",
    "- Creative, narrative summaries\n",
    "- When you need natural, flowing text\n",
    "- General-purpose summarization\n",
    "- When you have good prompting capabilities\n",
    "\n",
    "**Practical considerations:**\n",
    "- May hallucinate or add information\n",
    "- Require careful prompt engineering\n",
    "- Good for varying summary styles\n",
    "- Cost-effective for simple tasks\n",
    "\n",
    "**Example use cases:**\n",
    "- Blog post summaries\n",
    "- Creative writing summaries\n",
    "- Social media content\n",
    "\n",
    "### 2. Encoder-Only Models\n",
    "- Examples: BERT, RoBERTa\n",
    "**When to use:**\n",
    "- Extractive summarization\n",
    "- When you need to understand document context\n",
    "- Sentence ranking and selection\n",
    "- Classification-based approaches\n",
    "\n",
    "**Practical considerations:**\n",
    "- Limited generation capabilities\n",
    "- Excellent for understanding\n",
    "- Good for factual accuracy\n",
    "- Computationally efficient\n",
    "\n",
    "**Example use cases:**\n",
    "- News article key sentence extraction\n",
    "- Legal document important clause identification\n",
    "\n",
    "### 3. Encoder-Decoder Models\n",
    "**When to use:**\n",
    "- Balanced understanding and generation\n",
    "- Abstractive summarization\n",
    "- When you need both comprehension and creativity\n",
    "- Formal summarization tasks\n",
    "\n",
    "**Practical considerations:**\n",
    "- Higher computational requirements\n",
    "- Best for abstractive tasks\n",
    "- Good balance of accuracy and fluency\n",
    "- Requires more training data\n",
    "\n",
    "**Example use cases:**\n",
    "- Academic paper abstracts\n",
    "- Technical documentation summaries\n",
    "- Multi-document synthesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b4c5a0",
   "metadata": {},
   "source": [
    "<img src='images/llm_categories.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4603ad11",
   "metadata": {},
   "source": [
    "# **1.4 Basic Text Generation**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d1326a",
   "metadata": {},
   "source": [
    "#### Understanding Generation Parameters\n",
    "\n",
    "- **Temperature (0.0-2.0)**: Controls randomness\n",
    "  - 0.0-0.3: Deterministic, factual content\n",
    "  - 0.4-0.7: Balanced creativity and coherence  \n",
    "  - 0.8-1.2: Creative, varied output\n",
    "  - 1.3+: Highly creative but potentially incoherent\n",
    "\n",
    "- **Top-p (0.0-1.0)**: Nucleus sampling\n",
    "  - Selects the most probable tokens whose cumulative probability exceeds a certain threshold p\n",
    "  - Lower values: More focused, consistent\n",
    "  - Higher values: More diverse vocabulary\n",
    "\n",
    "- **Top-k**: Limits vocabulary to k most likely tokens and samples from it\n",
    "  - Lower values: More predictable\n",
    "  - Higher values: More creative word choices\n",
    "\n",
    "- **Beam-Search**\n",
    "<img src='images/beam-search.jpg' width=900 height=431>\n",
    "  -  Sequence score is cumulative sum of the log probability of every token in the beam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7f29a6",
   "metadata": {},
   "source": [
    "#### Hands-on Parameter Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7de9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the environment\n",
    "def is_colab():\n",
    "    try:\n",
    "        import google.colab\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "if is_colab():\n",
    "    from google.colab import userdata\n",
    "    api_key = userdata.get('OPENROUTER_API_KEY')\n",
    "else:\n",
    "  from dotenv import load_dotenv\n",
    "  load_dotenv()\n",
    "\n",
    "import os\n",
    "import dotenv\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from typing import List\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50b30eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMClient:\n",
    "\n",
    "    def __init__(self, model_name=\"google/gemini-2.0-flash-lite-001\"):\n",
    "        self.model = model_name\n",
    "        self.api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "        self.client = OpenAI(base_url=\"https://openrouter.ai/api/v1\", api_key=self.api_key)\n",
    "\n",
    "    def generate(self, text, temperature=0.8, max_tokens=2000, tools=None):\n",
    "        \"\"\"Generate text using autoregressive model\"\"\"\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": text}\n",
    "                ],\n",
    "                temperature=temperature,\n",
    "                max_tokens=max_tokens,\n",
    "                model=self.model,\n",
    "                tool_choice=\"auto\",\n",
    "                tools=tools,\n",
    "                extra_body={},\n",
    "            )\n",
    "            # Extract and return the response\n",
    "            result = response.choices[0].message.content\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde75d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_parameters(prompt: str, temperatures: List[float], client: LLMClient):\n",
    "\n",
    "    results = []\n",
    "    for temperature in temperatures:\n",
    "        result = client.generate(prompt, temperature=temperature)\n",
    "        results.append(\n",
    "            {\n",
    "                \"temperature\": temperature,\n",
    "                \"response\": result,\n",
    "                \"length\": len(result.split())\n",
    "            }\n",
    "        )   \n",
    "    return results\n",
    "\n",
    "\n",
    "test_prompt = \"Write a creative opening sentence for a science fiction story about time travel.\"\n",
    "temperatures = [0.1, 0.5, 0.9, 1.2]\n",
    "\n",
    "results = compare_parameters(test_prompt, temperatures, LLMClient()),\n",
    "for result in results[0]:\n",
    "    print(f\"Temperature: {result['temperature']}\"),\n",
    "    print(f\"Response: {result['response']}\"),\n",
    "    print(f\"Word count: {result['length']}\"),\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d821552e",
   "metadata": {},
   "source": [
    "#### Prompt Engineering Fundamentals\n",
    "\n",
    "\n",
    "<img src=\"images/co-star.png\" width=700 height=500>\n",
    "\n",
    "\n",
    "\n",
    "| Element       | Description                              |\n",
    "| ------------- | ---------------------------------------- |\n",
    "| **C**ontext   | Provide background information           |\n",
    "| **O**bjective | State the goal of the task               |\n",
    "| **S**tyle     | Specify tone, format, or constraints     |\n",
    "| **T**ask      | What the model should actually do        |\n",
    "| **A**udience  | Who the output is intended for           |\n",
    "| **R**esponse  | Clarify what the output should look like |\n",
    "\n",
    "**Prompt Example:**\n",
    "\n",
    "*Context*: You are a career advisor writing content for a university’s job preparation website. Many students are unsure how to describe their achievements on resumes, particularly in action-result format.\n",
    "\n",
    "*Objective*: Help students craft clear and impressive resume bullet points for internships in data science.\n",
    "\n",
    "*Style*: Keep the tone professional and concise. Use strong action verbs and quantify results wherever possible. Avoid first-person language.\n",
    "\n",
    "*Task*: Based on the details provided, generate 3 resume bullet points that follow best practices in resume writing.\n",
    "\n",
    "*Audience*: Undergraduate students applying for internships in data science roles.\n",
    "\n",
    "*Response*: Your output should be a bulleted list of exactly 3 resume-ready statements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed51980",
   "metadata": {},
   "source": [
    "## Structured output generation\n",
    "\n",
    "Getting LLMs to produce consistent, parseable output formats is crucial for integration with downstream systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d06996",
   "metadata": {},
   "source": [
    "### Prompt based structured generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ea843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    \"name\": \"string\",\n",
    "    \"age\": \"integer\",\n",
    "    \"profession\": \"string\",\n",
    "    \"language\": \"string\",\n",
    "    \"origin\": \"string\"\n",
    "}\n",
    "\n",
    "character_bio = \"\"\"\n",
    "\"Dr. Amara Liu is a 35-year-old astrophysicist from Shanghai. She researches dark matter and enjoys stargazing and sketching. Fluent in Mandarin and English.\"\n",
    "\"\"\"\n",
    "\n",
    "prompt = (\n",
    "    f\"{character_bio}\\n\\n\"\n",
    "    \"Extract the following structured data as JSON:\\n\"\n",
    "    f\"{json.dumps(schema, indent=2)}\\n\\n\"\n",
    "    \"Respond ONLY with valid JSON that matches the schema above.\"\n",
    ")\n",
    "llm_model = LLMClient()\n",
    "response = llm_model.generate(prompt)\n",
    "\n",
    "# Try to extract JSON\n",
    "try:\n",
    "    structured_data = json.loads(response)\n",
    "except json.JSONDecodeError:\n",
    "    import re\n",
    "    match = re.search(r'\\{.*\\}', response, re.DOTALL)\n",
    "    structured_data = json.loads(match.group()) if match else {\"error\": \"invalid format\"}\n",
    "\n",
    "print(structured_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db69e1b",
   "metadata": {},
   "source": [
    "### Schema Aware structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3985503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure Output via function calling\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"extract_profile\",\n",
    "            \"description\": \"Extracts a person's profile.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"name\": {\"type\": \"string\"},\n",
    "                    \"age\": {\"type\": \"integer\"},\n",
    "                    \"profession\": {\"type\": \"string\"},\n",
    "                    \"language\": {\"type\": \"string\"},\n",
    "                    \"origin\": {\"type\": \"string\"}\n",
    "                },\n",
    "                \"required\": [\"name\", \"age\", \"profession\", \"language\", \"origin\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "prompt = f\"What is the name, age, profession, language, and origin of the person in the following text:\\n {character_bio}\"\n",
    "response = llm_model.generate(prompt, tools=tools)\n",
    "print(response.choices[0].message.tool_calls[0].function.arguments)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0ba624",
   "metadata": {},
   "source": [
    "## Knowledge Check - Can you explain/do the following?\n",
    "\n",
    "### Conceptual Understanding\n",
    "- [ ] **Why did LLMs revolutionize summarization?**\n",
    "  - What changed from pre-2020 to post-2020 approaches?\n",
    "  - Why do simple prompts often outperform specialized models?\n",
    "\n",
    "- [ ] **Architecture Selection**\n",
    "  - When would you choose a decoder-only model (like GPT) for summarization?\n",
    "  - When would you choose an encoder-decoder model (like BART/T5)?\n",
    "  - What are the trade-offs between them?\n",
    "\n",
    "- [ ] **Parameter Control**\n",
    "  - How does temperature affect summary creativity vs. consistency?\n",
    "  - What's the difference between top-p and top-k sampling?\n",
    "  - When would you use low vs. high temperature for summarization?\n",
    "\n",
    "### Practical Skills\n",
    "- [ ] **Prompt Engineering**\n",
    "  - Can you structure a prompt using the CO-STAR framework?\n",
    "  - How would you modify a prompt to get a more focused summary?\n",
    "  - What would you do if your summary is too generic?\n",
    "\n",
    "- [ ] **Structured Output**\n",
    "  - Can you design a JSON schema for extracting key information?\n",
    "  - When would you use function calling vs. prompt-based structured generation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bfdf13",
   "metadata": {},
   "source": [
    "## Bridge to Part II: Prediction Exercise\n",
    "\n",
    "Before we dive into formal summarization techniques, make a prediction:\n",
    "\n",
    "**Scenario:** You need to summarize a 1000-word news article about a scientific breakthrough.\n",
    "\n",
    "**Question:** Which approach do you think will work better and why?\n",
    "\n",
    "A) **Extractive Approach**: Select the most important sentences from the original article\n",
    "B) **Abstractive Approach**: Generate a new summary using an LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3a754e",
   "metadata": {},
   "source": [
    "# **Part II - Core Summarization Techniques**\n",
    "\n",
    "By the end of Part II, participants should be able to:\n",
    "\n",
    "- Implement both extractive and abstractive summarization\n",
    "- Choose between zero-shot and few-shot approaches based on task requirements\n",
    "- Evaluate summary quality using multiple metrics\n",
    "- Understand the trade-offs between different summarization approaches\n",
    "- Apply domain-specific prompting strategies\n",
    "- Interpret evaluation results to improve summarization systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2bfed6",
   "metadata": {},
   "source": [
    "<img src=\"images/text summarization.jpg\" width=1000>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb6ec0c",
   "metadata": {},
   "source": [
    "## **2.1 Extractive Summarization**\n",
    "\n",
    "Extractive summarization selects the most important sentences from the orginal text to create the summary.\n",
    "\n",
    "## The Basic Process:\n",
    "1. Score sentences based on importance\n",
    "2. Select top-scoring sentences using ranking algorithm (TF IDF, SVM, etc)\n",
    "3. Arrange in coherent order (usually original order)\n",
    "\n",
    "## Advantages:\n",
    "- Factually accurate (uses original text)\n",
    "- Computationally efficient\n",
    "- Works well for objective content\n",
    "\n",
    "## Disadvantages:\n",
    "- May be disconnected or redundant\n",
    "- Cannot reformulate or simplify complex content\n",
    "- Limited by quality of source material"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093db879",
   "metadata": {},
   "source": [
    "## Understanding TF-IDF for Extractive Summarization\n",
    "\n",
    "**TF-IDF (Term Frequency-Inverse Document Frequency)** is a numerical statistic that reflects how important a word is to a document within a collection of documents. It's widely used in information retrieval and text mining, making it perfect for identifying the most important sentences in a document for summarization.\n",
    "\n",
    "## The Mathematical Foundation\n",
    "\n",
    "### Term Frequency (TF)\n",
    "**Definition**: How frequently a word appears in a specific sentence/document.\n",
    "\n",
    "$$TF(word, sentence) = \\frac{\\text{Number of times word appears in sentence}}{\\text{Total number of words in sentence}}$$\n",
    "\n",
    "**Example**: In the sentence \"The cat sat on the mat\", the word \"the\" has TF = 2/6 = 0.33\n",
    "\n",
    "### Inverse Document Frequency (IDF)\n",
    "**Definition**: How rare or common a word is across all sentences in the document.\n",
    "\n",
    "$$IDF(word) = \\log\\left(\\frac{\\text{Total number of sentences}}{\\text{Number of sentences containing the word}}\\right)$$\n",
    "\n",
    "**Intuition**: \n",
    "- Common words (like \"the\", \"and\") appear in many sentences → Low IDF → Less important\n",
    "- Rare words (like \"quantum\", \"photosynthesis\") appear in few sentences → High IDF → More important\n",
    "\n",
    "### TF-IDF Score\n",
    "**Final Formula**:\n",
    "$$TF\\text{-}IDF(word, sentence) = TF(word, sentence) \\times IDF(word)$$\n",
    "\n",
    "**Sentence Score**: Sum of TF-IDF scores for all words in the sentence\n",
    "$$Score(sentence) = \\sum_{word \\in sentence} TF\\text{-}IDF(word, sentence)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ef4670",
   "metadata": {},
   "source": [
    "## Visual Example\n",
    "\n",
    "Let's work through a simple example:\n",
    "\n",
    "**Document**: \n",
    "- Sentence 1: \"The cat sat on the mat\"\n",
    "- Sentence 2: \"The dog ran quickly\"  \n",
    "- Sentence 3: \"Cats and dogs are pets\"\n",
    "\n",
    "### Step 1: Calculate TF for each word in Sentence 1\n",
    "\n",
    "| Word | Count in S1 | Total words in S1 | TF |\n",
    "|------|-------------|-------------------|-----|\n",
    "| the  | 2           | 6                 | 0.33|\n",
    "| cat  | 1           | 6                 | 0.17|\n",
    "| sat  | 1           | 6                 | 0.17|\n",
    "| on   | 1           | 6                 | 0.17|\n",
    "| mat  | 1           | 6                 | 0.17|\n",
    "\n",
    "### Step 2: Calculate IDF for each word\n",
    "\n",
    "| Word | Sentences containing word | Total sentences | IDF |\n",
    "|------|--------------------------|----------------|-----|\n",
    "| the  | 2 (S1, S2)              | 3              | log(3/2) = 0.18|\n",
    "| cat  | 1 (S1)                  | 3              | log(3/1) = 0.48|\n",
    "| sat  | 1 (S1)                  | 3              | log(3/1) = 0.48|\n",
    "\n",
    "### Step 3: Calculate TF-IDF scores\n",
    "\n",
    "| Word | TF   | IDF  | TF-IDF |\n",
    "|------|------|------|--------|\n",
    "| the  | 0.33 | 0.18 | 0.06   |\n",
    "| cat  | 0.17 | 0.48 | 0.08   |\n",
    "| sat  | 0.17 | 0.48 | 0.08   |\n",
    "\n",
    "**Sentence 1 Score** = 0.06 + 0.08 + 0.08 + ... = Final Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eed9d4",
   "metadata": {},
   "source": [
    "### Why TF-IDF Works for Summarization\n",
    "\n",
    "### 1. **Identifies Content Words**\n",
    "- Function words (\"the\", \"and\", \"is\") get low scores\n",
    "- Content words (\"algorithm\", \"photosynthesis\", \"democracy\") get high scores\n",
    "\n",
    "### 2. **Balances Frequency and Rarity**\n",
    "- A word mentioned often in one sentence (high TF) but rare overall (high IDF) = very important\n",
    "- A word mentioned everywhere (low IDF) = less distinctive\n",
    "\n",
    "### 3. **Context Awareness**\n",
    "- Same word gets different importance scores in different documents\n",
    "- Adapts to the specific content being summarized\n",
    "\n",
    "### Issues with TF-IDF\n",
    "1. \n",
    "- **Problem**: TF-IDF ignores where sentences appear in the document.\n",
    "- **Solution**: Add position-based scoring.\n",
    "\n",
    "2. \n",
    "- **Problem**: Longer sentences automatically get higher TF-IDF scores.\n",
    "- **Solution**: Normalize by optimal sentence length.\n",
    "\n",
    "3. \n",
    "- **Problem**: Multiple sentences might convey the same information.\n",
    "- **Solution**: Remove semantically similar sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7db391e",
   "metadata": {},
   "source": [
    "Hands on Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfba888d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt') \n",
    "nltk.download('stopwords') \n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "class ExtractiveSummarizer:\n",
    "    \"\"\"Enhanced extractive summarizer using proper TF-IDF and additional features\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"Clean and prepare text for processing\"\"\"\n",
    "        # Remove extra whitespace and normalize\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        return text\n",
    "    \n",
    "    def extract_sentences(self, text):\n",
    "        \"\"\"Extract and clean sentences\"\"\"\n",
    "        sentences = sent_tokenize(text)\n",
    "        # Filter out very short sentences (less than 5 words)\n",
    "        sentences = [s for s in sentences if len(s.split()) >= 5]\n",
    "        return sentences\n",
    "    \n",
    "    def calculate_tfidf_scores(self, sentences):\n",
    "        \"\"\"Calculate TF-IDF scores for sentences\"\"\"\n",
    "        # Use sklearn's TfidfVectorizer for proper TF-IDF calculation\n",
    "        vectorizer = TfidfVectorizer(\n",
    "            stop_words='english',\n",
    "            lowercase=True,\n",
    "            max_features=1000,\n",
    "            ngram_range=(1, 2)  # Include bigrams for better context\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            tfidf_matrix = vectorizer.fit_transform(sentences)\n",
    "            # Sum TF-IDF scores for each sentence\n",
    "            sentence_scores = np.array(tfidf_matrix.sum(axis=1)).flatten()\n",
    "            return sentence_scores\n",
    "        except ValueError:\n",
    "            print('failed to get tf-idf')\n",
    "            # Fallback to simple word frequency if TF-IDF fails\n",
    "\n",
    "    def calculate_position_scores(self, sentences):\n",
    "        \"\"\"Calculate position-based scores (first and last sentences are important)\"\"\"\n",
    "        num_sentences = len(sentences)\n",
    "        position_scores = np.zeros(num_sentences)\n",
    "        \n",
    "        for i in range(num_sentences):\n",
    "            if i == 0:  # First sentence\n",
    "                position_scores[i] = 0.3\n",
    "            elif i == num_sentences - 1:  # Last sentence\n",
    "                position_scores[i] = 0.2\n",
    "            elif i < num_sentences * 0.1:  # Early sentences\n",
    "                position_scores[i] = 0.15\n",
    "            elif i > num_sentences * 0.9:  # Late sentences\n",
    "                position_scores[i] = 0.1\n",
    "            else:\n",
    "                position_scores[i] = 0.05\n",
    "        \n",
    "        return position_scores\n",
    "                \n",
    "    def calculate_sentence_length_scores(self, sentences):\n",
    "        \"\"\"Normalize scores by sentence length to avoid bias toward longer sentences\"\"\"\n",
    "        length_scores = []\n",
    "        for sentence in sentences:\n",
    "            words = sentence.split()\n",
    "            # Optimal sentence length is around 15-25 words\n",
    "            if 15 <= len(words) <= 25:\n",
    "                length_scores.append(1.0)\n",
    "            elif 10 <= len(words) < 15 or 25 < len(words) <= 35:\n",
    "                length_scores.append(0.8)\n",
    "            else:\n",
    "                length_scores.append(0.6)\n",
    "        \n",
    "        return np.array(length_scores)\n",
    "\n",
    "    def remove_redundant_sentences(self, sentences, selected_indices, threshold=0.7):\n",
    "        \"\"\"Remove sentences that are too similar to already selected ones\"\"\"\n",
    "        if len(selected_indices) <= 1:\n",
    "            return selected_indices\n",
    "        \n",
    "        # Use simple word overlap for similarity\n",
    "        filtered_indices = [selected_indices[0]]  # Keep the first (highest scoring)\n",
    "        \n",
    "        for idx in selected_indices[1:]:\n",
    "            current_sentence = sentences[idx]\n",
    "            current_words = set(word.lower() for word in word_tokenize(current_sentence)\n",
    "                              if word.lower() not in self.stop_words and word.isalnum())\n",
    "            \n",
    "            is_redundant = False\n",
    "            for selected_idx in filtered_indices:\n",
    "                selected_sentence = sentences[selected_idx]\n",
    "                selected_words = set(word.lower() for word in word_tokenize(selected_sentence)\n",
    "                                   if word.lower() not in self.stop_words and word.isalnum())\n",
    "                \n",
    "                # Calculate Jaccard similarity\n",
    "                if len(current_words) > 0 and len(selected_words) > 0:\n",
    "                    intersection = current_words.intersection(selected_words)\n",
    "                    union = current_words.union(selected_words)\n",
    "                    similarity = len(intersection) / len(union)\n",
    "                    \n",
    "                    if similarity > threshold:\n",
    "                        is_redundant = True\n",
    "                        break\n",
    "            \n",
    "            if not is_redundant:\n",
    "                filtered_indices.append(idx)\n",
    "        \n",
    "        return filtered_indices\n",
    "    \n",
    "    def summarize(self, text, ratio=0.3, max_sentences=None):\n",
    "        \"\"\"\n",
    "        Generate extractive summary using improved TF-IDF approach\n",
    "        \n",
    "        Args:\n",
    "            text: Input text to summarize\n",
    "            ratio: Proportion of sentences to include (0.1 to 0.5)\n",
    "            max_sentences: Maximum number of sentences (overrides ratio if specified)\n",
    "        \"\"\"\n",
    "        # Preprocess and extract sentences\n",
    "        text = self.preprocess_text(text)\n",
    "        sentences = self.extract_sentences(text)\n",
    "        \n",
    "        if len(sentences) <= 2:\n",
    "            return ' '.join(sentences)\n",
    "        \n",
    "        # Calculate different scoring components\n",
    "        tfidf_scores = self.calculate_tfidf_scores(sentences)\n",
    "        position_scores = self.calculate_position_scores(sentences)\n",
    "        length_scores = self.calculate_sentence_length_scores(sentences)\n",
    "        \n",
    "        # Normalize TF-IDF scores to 0-1 range\n",
    "        if tfidf_scores.max() > 0:\n",
    "            tfidf_scores = tfidf_scores / tfidf_scores.max()\n",
    "        \n",
    "        # Combine scores with weights\n",
    "        final_scores = (\n",
    "            0.7 * tfidf_scores +      # Content importance (70%)\n",
    "            0.2 * position_scores +   # Position importance (20%)\n",
    "            0.1 * length_scores       # Length preference (10%)\n",
    "        )\n",
    "        \n",
    "        # Determine number of sentences to select\n",
    "        if max_sentences:\n",
    "            num_sentences = min(max_sentences, len(sentences))\n",
    "        else:\n",
    "            num_sentences = max(1, int(len(sentences) * ratio))\n",
    "        \n",
    "        # Select top sentences\n",
    "        top_indices = np.argsort(final_scores)[-num_sentences:][::-1]\n",
    "        \n",
    "        # Remove redundant sentences\n",
    "        filtered_indices = self.remove_redundant_sentences(sentences, top_indices)\n",
    "        \n",
    "        # Sort by original order in text\n",
    "        filtered_indices.sort()\n",
    "        \n",
    "        # Create summary\n",
    "        summary_sentences = [sentences[i] for i in filtered_indices]\n",
    "        summary = ' '.join(summary_sentences)\n",
    "        \n",
    "        return summary, {\n",
    "            'selected_indices': filtered_indices,\n",
    "            'scores': final_scores,\n",
    "            'num_original_sentences': len(sentences),\n",
    "            'num_selected_sentences': len(filtered_indices)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ba4f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "\n",
    "# Load an article\n",
    "with open('articles/article.txt', 'r', encoding='utf-8') as f:\n",
    "    article = f.read()\n",
    "    \n",
    "# Print article length\n",
    "print(f\"Article contains {len(sent_tokenize(article))} sentences and {len(article.split())} words\")\n",
    "\n",
    "extractive_summarizer = ExtractiveSummarizer()\n",
    "generated_summary= extractive_summarizer.summarize(article, ratio=0.3)\n",
    "print(f\"\\nExtractive Summary\\n{generated_summary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a1b720",
   "metadata": {},
   "source": [
    "## **2.2 Abstractive Summarization & Control Parameters**\n",
    "By the end of Part II, participants should be able to:\n",
    "\n",
    "Implement both extractive and abstractive summarization\n",
    "Choose between zero-shot and few-shot approaches based on task requirements\n",
    "Evaluate summary quality using multiple metrics\n",
    "Understand the trade-offs between different summarization approaches\n",
    "Apply domain-specific prompting strategies\n",
    "Interpret evaluation results to improve summarization systems\n",
    "\n",
    "## What is Abstractive Summarization?\n",
    "\n",
    "Abstractive summarization involves:\n",
    "- Understanding the source content deeply\n",
    "- Identifying key concepts and relationships\n",
    "- Generating new text by paraphrasing existing text\n",
    "- Condensing information in ways that extraction cannot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33186fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbstractiveSummarizer(LLMClient): \n",
    "    \"\"\"Specialized class for abstractive summarization techniques\"\"\"\n",
    "    \n",
    "    def zero_shot_summarize(self, text, instruction=\"Summarize the following text:\",\n",
    "                            length=None, style=None, focus=None, audience=None):\n",
    "        \"\"\"Enhanced zero-shot with summarization-specific improvements\"\"\"\n",
    "        # Build enhanced prompt with controls\n",
    "        prompt_parts = []\n",
    "        \n",
    "        # Base instruction\n",
    "        if audience:\n",
    "            prompt_parts.append(f\"You are writing for {audience}.\")\n",
    "        \n",
    "        # Style control\n",
    "        if style:\n",
    "            style_modifiers = {\n",
    "                \"formal\": \"Write in a formal, professional tone.\",\n",
    "                \"casual\": \"Use a conversational, accessible tone.\",\n",
    "                \"technical\": \"Use precise technical language.\",\n",
    "                \"journalistic\": \"Write in news article style.\"\n",
    "            }\n",
    "            prompt_parts.append(style_modifiers.get(style, \"\"))\n",
    "        \n",
    "        # Length control\n",
    "        if length:\n",
    "            length_modifiers = {\n",
    "                \"brief\": \"Keep it to 2-3 sentences maximum.\",\n",
    "                \"medium\": \"Aim for 4-6 sentences.\",\n",
    "                \"detailed\": \"Provide 8-10 sentences with comprehensive coverage.\"\n",
    "            }\n",
    "            prompt_parts.append(length_modifiers.get(length, \"\"))\n",
    "        \n",
    "        # Focus control\n",
    "        if focus:\n",
    "            prompt_parts.append(f\"Pay special attention to: {', '.join(focus)}.\")\n",
    "        \n",
    "        # Combine all parts\n",
    "        enhanced_instruction = \" \".join(prompt_parts) + f\" {instruction}\"\n",
    "        \n",
    "        prompt = f\"{enhanced_instruction}\\n\\n{text}\\n\\nSummary:\"\n",
    "        return self.generate(prompt)\n",
    "    \n",
    "    def few_shot_summarize(self, text, examples):\n",
    "        \"\"\"Few-shot summarization with examples\"\"\"\n",
    "        prompt = \"Here are examples of good summaries:\\n\\n\"\n",
    "        \n",
    "        for i, example in enumerate(examples, 1):\n",
    "            prompt += f\"Example {i}:\\n\"\n",
    "            prompt += f\"Text: {example['text']}\\n\"\n",
    "            prompt += f\"Summary: {example['summary']}\\n\\n\"\n",
    "        \n",
    "        prompt += f\"Now summarize this text:\\n{text}\\n\\nSummary:\"\n",
    "        return self.generate(prompt)\n",
    "        \n",
    "    def compare_few_shot_vs_zero_shot(self, text, examples):\n",
    "        \"\"\"Compare zero-shot and few-shot performance\"\"\"\n",
    "        \n",
    "        # Zero-shot\n",
    "        zero_shot = self.zero_shot_summarize(text)\n",
    "        \n",
    "        # Few-shot\n",
    "        few_shot = self.few_shot_summarize(text, examples)\n",
    "        \n",
    "        print(\"ZERO-SHOT SUMMARY:\")\n",
    "        print(zero_shot)\n",
    "        print(f\"Length: {len(zero_shot.split())} words\\n\")\n",
    "        \n",
    "        print(\"FEW-SHOT SUMMARY:\")\n",
    "        print(few_shot)\n",
    "        print(f\"Length: {len(few_shot.split())} words\\n\")\n",
    "        \n",
    "        return zero_shot, few_shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc67bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#few-shot examples for different domains\n",
    "news_examples = [\n",
    "    {\n",
    "        \"text\": \"Scientists at MIT have developed a new battery technology that could revolutionize electric vehicles. The lithium-metal batteries can charge to 80% capacity in just 10 minutes and last for over 500,000 miles. The breakthrough addresses two major concerns about electric vehicles: charging time and battery longevity. Commercial production is expected to begin in 2026.\",\n",
    "        \"summary\": \"MIT scientists created fast-charging, long-lasting batteries for electric vehicles, addressing key concerns about charging time and durability, with commercial production planned for 2026.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"The Federal Reserve announced a 0.25% interest rate cut today, citing concerns about slowing economic growth and inflation falling below target levels. This marks the third rate cut this year. Stock markets responded positively, with the S&P 500 gaining 2.1% in after-hours trading. Economists predict this could stimulate business investment and consumer spending.\",\n",
    "        \"summary\": \"The Federal Reserve cut interest rates by 0.25% due to economic concerns, prompting positive market reactions and expectations of increased business and consumer activity.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "research_examples = [\n",
    "    {\n",
    "        \"text\": \"This study examined the effects of meditation on stress hormones in 200 participants over 8 weeks. Participants who meditated daily showed a 23% reduction in cortisol levels compared to the control group. The research also found improvements in sleep quality and self-reported well-being. These findings suggest meditation could be an effective intervention for stress management.\",\n",
    "        \"summary\": \"An 8-week study of 200 participants found daily meditation reduced stress hormone levels by 23% and improved sleep and well-being, supporting meditation as a stress management tool.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# Test with a new research article\n",
    "new_research = \"\"\"\n",
    "A comprehensive analysis of social media usage patterns among teenagers reveals concerning trends in mental health outcomes. The study, following 1,500 participants aged 13-18 over two years, found that teens spending more than 3 hours daily on social platforms showed increased rates of anxiety and depression. Particularly concerning was the correlation between late-night social media use and sleep disorders. However, the research also identified positive outcomes, including enhanced social connections and access to mental health resources. The researchers recommend implementing digital wellness programs in schools and encouraging mindful social media usage rather than complete avoidance.\n",
    "\"\"\"\n",
    "abstractive_summarizer = AbstractiveSummarizer()\n",
    "zero_shot_result, few_shot_result = abstractive_summarizer.compare_few_shot_vs_zero_shot(new_research, research_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741622dd",
   "metadata": {},
   "source": [
    "###  Discussion Point\n",
    "After running the above experiment:\n",
    "1. Which summary feels more consistent with the examples provided?\n",
    "2. How did the few-shot examples influence the style and content selection?\n",
    "3. What are the trade-offs between zero-shot (faster) and few-shot (more controlled)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f4d123",
   "metadata": {},
   "source": [
    "### Advanced Prompt Engineering for Summarization\n",
    "\n",
    "When dealing with complex documents with multiple topics or intricate relationships, breaking down the summarization process helps LLMs produce better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ca94df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedSummarizationPrompting:\n",
    "    \"\"\"Advanced prompting strategies specifically for summarization\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.prompt_templates = self._load_templates()\n",
    "        self.quality_checks = self._load_quality_prompts()\n",
    "    \n",
    "    def _load_templates(self):\n",
    "        \"\"\"Summarization-specific prompt templates\"\"\"\n",
    "        return {\n",
    "            \"news_summary\": {\n",
    "                \"template\": \"\"\"\n",
    "                Context: You are a professional news editor creating summaries for busy readers.\n",
    "                Objective: Create a concise summary that captures the key facts and implications.\n",
    "                Style: Objective, factual, following inverted pyramid structure.\n",
    "                Task: Summarize the following news article.\n",
    "                Audience: General public seeking quick news updates.\n",
    "                Response: Provide a 3-sentence summary focusing on who, what, when, where, why.\n",
    "                \n",
    "                Article: {text}\n",
    "                \n",
    "                News Summary:\n",
    "                \"\"\",\n",
    "                \"parameters\": {\"temperature\": 0.2, \"top_p\": 0.8}\n",
    "            },\n",
    "            \n",
    "            \"research_synthesis\": {\n",
    "                \"template\": \"\"\"\n",
    "                Context: You are a research analyst synthesizing academic content.\n",
    "                Objective: Extract key findings and methodological insights.\n",
    "                Style: Academic but accessible, emphasizing evidence and conclusions.\n",
    "                Task: Summarize this research for {audience}.\n",
    "                Audience: {audience}\n",
    "                Response: Structure as Background, Methods, Results, Implications.\n",
    "                \n",
    "                Research: {text}\n",
    "                \n",
    "                Research Summary:\n",
    "                \"\"\",\n",
    "                \"parameters\": {\"temperature\": 0.3, \"top_p\": 0.85}\n",
    "            },\n",
    "            \n",
    "            \"meeting_minutes\": {\n",
    "                \"template\": \"\"\"\n",
    "                Context: You are an executive assistant creating actionable meeting summaries.\n",
    "                Objective: Capture decisions, action items, and next steps.\n",
    "                Style: Structured, action-oriented, clear responsibilities.\n",
    "                Task: Convert this meeting transcript into organized minutes.\n",
    "                Audience: Meeting participants and stakeholders.\n",
    "                Response: Format as Decisions Made, Action Items, Discussion Points, Next Steps.\n",
    "                \n",
    "                Transcript: {text}\n",
    "                \n",
    "                Meeting Minutes:\n",
    "                \"\"\",\n",
    "                \"parameters\": {\"temperature\": 0.1, \"top_p\": 0.7}\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _load_quality_prompts(self):\n",
    "        \"\"\"Quality control and refinement prompts\"\"\"\n",
    "        return {\n",
    "            \"factuality_check\": \"\"\"\n",
    "            Review this summary for factual accuracy against the source:\n",
    "            Source: {source}\n",
    "            Summary: {summary}\n",
    "            \n",
    "            Check for:\n",
    "            1. Factual errors or misrepresentations\n",
    "            2. Added information not in source\n",
    "            3. Missing critical information\n",
    "            \n",
    "            Factuality Assessment:\n",
    "            \"\"\",\n",
    "            \n",
    "            \"coherence_improvement\": \"\"\"\n",
    "            Improve the coherence and flow of this summary:\n",
    "            Original: {summary}\n",
    "            \n",
    "            Make it more coherent by:\n",
    "            1. Better transitions between ideas\n",
    "            2. Logical information ordering\n",
    "            3. Clearer connections between points\n",
    "            \n",
    "            Improved Summary:\n",
    "            \"\"\",\n",
    "            \n",
    "            \"audience_adaptation\": \"\"\"\n",
    "            Adapt this summary for a {target_audience} audience:\n",
    "            Original: {summary}\n",
    "            Current audience: {current_audience}\n",
    "            Target audience: {target_audience}\n",
    "            \n",
    "            Adapted Summary:\n",
    "            \"\"\"\n",
    "        }\n",
    "    \n",
    "    def generate_domain_summary(self, text, domain=\"news\", audience=\"general\", **kwargs):\n",
    "        \"\"\"Generate summary using domain-specific prompting\"\"\"\n",
    "        template = self.prompt_templates.get(domain, self.prompt_templates[\"news_summary\"])\n",
    "        \n",
    "        prompt = template[\"template\"].format(\n",
    "            text=text, \n",
    "            audience=audience,\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "        # Use domain-specific parameters\n",
    "        params = template[\"parameters\"]\n",
    "        return self.generate(prompt, **params)\n",
    "    \n",
    "    def multi_step_summarization(self, text, steps=None):\n",
    "        \"\"\"Chain-of-thought summarization for complex documents\"\"\"\n",
    "        if steps is None:\n",
    "            steps = [\"identify_topics\", \"extract_key_points\", \"synthesize\"]\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # Step 1: Topic identification\n",
    "        if \"identify_topics\" in steps:\n",
    "            topic_prompt = f\"\"\"\n",
    "            Step 1: Identify the main topics and themes in this text.\n",
    "            List 3-5 key topics with brief descriptions.\n",
    "            \n",
    "            Text: {text}\n",
    "            \n",
    "            Main Topics:\n",
    "            \"\"\"\n",
    "            results[\"topics\"] = self.generate(topic_prompt, temperature=0.3)\n",
    "        \n",
    "        # Step 2: Key point extraction\n",
    "        if \"extract_key_points\" in steps:\n",
    "            points_prompt = f\"\"\"\n",
    "            Step 2: For each topic identified below, extract the key points from the text.\n",
    "            \n",
    "            Topics: {results.get('topics', 'Not identified')}\n",
    "            Text: {text}\n",
    "            \n",
    "            Key Points by Topic:\n",
    "            \"\"\"\n",
    "            results[\"key_points\"] = self.generate(points_prompt, temperature=0.2)\n",
    "        \n",
    "        # Step 3: Synthesis\n",
    "        if \"synthesize\" in steps:\n",
    "            synthesis_prompt = f\"\"\"\n",
    "            Step 3: Synthesize the following analysis into a coherent summary.\n",
    "            \n",
    "            Topics: {results.get('topics', '')}\n",
    "            Key Points: {results.get('key_points', '')}\n",
    "            \n",
    "            Create a flowing summary that integrates all important information:\n",
    "            \n",
    "            Final Summary:\n",
    "            \"\"\"\n",
    "            results[\"final_summary\"] = self.generate(synthesis_prompt, temperature=0.4)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def quality_control_pipeline(self, text, summary):\n",
    "        \"\"\"Apply quality control checks and improvements\"\"\"\n",
    "        # Check factuality\n",
    "        factuality = self.generate(\n",
    "            self.quality_checks[\"factuality_check\"].format(\n",
    "                source=text, summary=summary\n",
    "            ), temperature=0.1\n",
    "        )\n",
    "        \n",
    "        # Improve coherence if needed\n",
    "        improved_summary = self.generate(\n",
    "            self.quality_checks[\"coherence_improvement\"].format(\n",
    "                summary=summary\n",
    "            ), temperature=0.3\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"original_summary\": summary,\n",
    "            \"factuality_check\": factuality,\n",
    "            \"improved_summary\": improved_summary\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6df83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"articles/article.txt\", 'r', encoding='utf-8') as f:\n",
    "    article_text = f.read()\n",
    "with open(\"articles/complex_article.txt\", 'r', encoding='utf-8') as f:\n",
    "    complex_article_text = f.read()\n",
    "\n",
    "def demonstrate_advanced_prompting():\n",
    "    \"\"\"Demonstrate all advanced prompting techniques\"\"\"\n",
    "    \n",
    "    advanced_prompter = AdvancedSummarizationPrompting()\n",
    "    \n",
    "    # Domain-specific summarization\n",
    "    news_summary = advanced_prompter.generate_domain_summary(\n",
    "        article_text, \n",
    "        domain=\"news\", \n",
    "        audience=\"general public\"\n",
    "    )\n",
    "    \n",
    "    # Multi-step summarization\n",
    "    complex_summary = advanced_prompter.multi_step_summarization(\n",
    "        complex_article_text\n",
    "    )\n",
    "    \n",
    "    # Quality control\n",
    "    quality_results = advanced_prompter.quality_control_pipeline(\n",
    "        article_text, \n",
    "        news_summary\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"domain_specific\": news_summary,\n",
    "        \"multi_step\": complex_summary,\n",
    "        \"quality_controlled\": quality_results\n",
    "    }\n",
    "\n",
    "advanced_prompting_results = demonstrate_advanced_prompting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd54afc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_with_prompts():\n",
    "    \"\"\"Experiment with different instruction styles\"\"\"\n",
    "    \n",
    "    instructions = {\n",
    "        \"basic\": \"Summarize the following text:\",\n",
    "        \"concise\": \"Provide a concise summary of the main points:\",\n",
    "        \"detailed\": \"Write a comprehensive summary covering all key aspects:\",\n",
    "        \"bullet\": \"Summarize the key points as bullet points:\",\n",
    "        \"executive\": \"Write an executive summary focusing on implications and next steps:\"\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for style, instruction in instructions.items():\n",
    "        print(f\"\\n--- {style.upper()} STYLE ---\")\n",
    "        summary = abstractive_summarizer.zero_shot_summarize(article, instruction)\n",
    "        results[style] = summary\n",
    "        print(f\"Instruction: {instruction}\")\n",
    "        print(f\"Summary: {summary}\")\n",
    "        print(f\"Length: {len(summary.split())} words\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "instruction_results = experiment_with_prompts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f13ebb",
   "metadata": {},
   "source": [
    "## **2.3 Evaluation Metrics for Summarization**\n",
    "\n",
    "How do we know if our summaries are good? Let's implement some common evaluation metrics:\n",
    "\n",
    "### ROUGE (Recall-Oriented Understudy for Gisting Evaluation)\n",
    "- Measures overlap between machine-generated summary and reference summary\n",
    "- ROUGE-N: N-gram recall\n",
    "- ROUGE-L: Longest Common Subsequence \n",
    "\n",
    "<img src='images/Rouge L.jpeg' width=700>\n",
    "\n",
    "LCS is the longest set of ordered tokens that occurs in both sequences (Ref, Gen)\n",
    "\n",
    "### BLEU (Bilingual Evaluation Understudy)\n",
    "- Originally designed for translation, but used for summarization\n",
    "- Precision-focused (how many generated n-grams appear in reference)\n",
    "\n",
    "### BERTScore\n",
    "- Uses contextual embeddings to compute similarity\n",
    "- Better semantic understanding than n-gram methods\n",
    "\n",
    "### Human Evaluation Dimensions\n",
    "- **Relevance**: How well does the summary capture the main points?\n",
    "- **Coherence**: Does it flow logically?\n",
    "- **Fluency**: Is it grammatically correct?\n",
    "- **Factuality**: Does it contain errors or hallucinations?\n",
    "- **Accuracy**: Does the summary accurately represent the original content?\n",
    "- **Readability**: Is the summary well-written and easy to understand?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2462107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement custom ROUGE socre\n",
    "from collections import Counter\n",
    "\n",
    "# Reference summary for comparison\n",
    "with open(\"articles/reference summary.txt\", 'r', encoding='utf-8') as f:\n",
    "    reference_summary = f.read()\n",
    "\n",
    "\n",
    "def calculate_rouge_n(reference_summary, generated_summary, n):\n",
    "    \"\"\"Calculate ROUGE-N score\"\"\"\n",
    "    # Tokenize into words\n",
    "    ref_tokens = word_tokenize(reference_summary.lower())\n",
    "    cand_tokens = word_tokenize(generated_summary.lower())\n",
    "\n",
    "    # Generate n-grams\n",
    "    ref_ngrams = list(zip(*[ref_tokens[i:] for i in range(n)]))\n",
    "    cand_ngrams = list(zip(*[cand_tokens[i:] for i in range(n)]))\n",
    "    \n",
    "    # Count ngrams\n",
    "    ref_counter = Counter(ref_ngrams)\n",
    "    cand_counter = Counter(cand_ngrams)\n",
    "    \n",
    "    # Count matches\n",
    "    overlap = sum((ref_counter & cand_counter).values()) # intersection of the two counters\n",
    "\n",
    "    # Calculate precision and recall\n",
    "    precision = overlap / max(1, sum(cand_counter.values()))\n",
    "    recall = overlap / max(1, sum(ref_counter.values()))\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1 = 2 * precision * recall / max(1, precision + recall)\n",
    "    return f1\n",
    "\n",
    "def calculate_rouge_l(reference_summary, generated_summary):\n",
    "    \"\"\"Calculate ROUGE-L (Longest Common Subsequence)\"\"\"\n",
    "    \n",
    "    def lcs_length(X, Y):\n",
    "        m, n = len(X), len(Y)\n",
    "        L = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "        \n",
    "        for i in range(1, m + 1):\n",
    "            for j in range(1, n + 1):\n",
    "                if X[i-1] == Y[j-1]:\n",
    "                    L[i][j] = L[i-1][j-1] + 1\n",
    "                else:\n",
    "                    L[i][j] = max(L[i-1][j], L[i][j-1])\n",
    "        \n",
    "        return L[m][n]\n",
    "    \n",
    "    # Tokenize\n",
    "    ref_tokens = word_tokenize(reference_summary.lower())\n",
    "    gen_tokens = word_tokenize(generated_summary.lower())\n",
    "    \n",
    "    # Calculate LCS\n",
    "    lcs_len = lcs_length(ref_tokens, gen_tokens)\n",
    "    \n",
    "    # Calculate precision, recall, F1\n",
    "    precision = lcs_len / max(1, len(gen_tokens))\n",
    "    recall = lcs_len / max(1, len(ref_tokens))\n",
    "    f1 = 2 * precision * recall / max(1, precision + recall)\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdcaefb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a simple function to evaluate our summaries for ROUGE-1 and ROUGE-2\n",
    "def evaluate_summary(reference, candidate):\n",
    "    \"\"\"Evaluate a summary using multiple metrics\"\"\"\n",
    "    scores = {\n",
    "        'ROUGE-1': calculate_rouge_n(reference, candidate, 1),\n",
    "        'ROUGE-2': calculate_rouge_n(reference, candidate, 2),\n",
    "    }\n",
    "\n",
    "    # Add readability metric: average words per sentence\n",
    "    cand_sentences = sent_tokenize(candidate)\n",
    "    avg_sentence_length = len(word_tokenize(candidate)) / max(1, len(cand_sentences))\n",
    "    scores['Avg Words/Sentence'] = avg_sentence_length\n",
    "    \n",
    "    return scores\n",
    "\n",
    "# Evaluate our extractive summary against the reference\n",
    "evaluation_scores = evaluate_summary(reference_summary, generated_summary)\n",
    "\n",
    "print(\"Evaluation Results:\")\n",
    "for metric, score in evaluation_scores.items():\n",
    "    print(f\"{metric}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885016ed",
   "metadata": {},
   "source": [
    "# **Part III - Advanced Applications**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6ae0db",
   "metadata": {},
   "source": [
    "## **3.1 Complex Document Handling**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c208435",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LongDocumentSummarizer(AbstractiveSummarizer):\n",
    "    \"\"\"Specialized summarizer for handling long documents\"\"\"\n",
    "    \n",
    "    def chunk_text(self, text, chunk_size=1000, overlap=100):\n",
    "        \"\"\"Split text into overlapping chunks\"\"\"\n",
    "        words = text.split()\n",
    "        chunks = []\n",
    "        \n",
    "        for i in range(0, len(words), chunk_size - overlap):\n",
    "            chunk = ' '.join(words[i:i + chunk_size])\n",
    "            chunks.append(chunk)\n",
    "            \n",
    "            if i + chunk_size >= len(words):\n",
    "                break\n",
    "        \n",
    "        return chunks\n",
    "    \n",
    "    def recursive_summarize(self, text, target_length=200, max_iterations=3):\n",
    "        \"\"\"Recursively summarize long text\"\"\"\n",
    "        \n",
    "        print(f\"📄 Starting recursive summarization...\")\n",
    "        print(f\"Original length: {len(text.split())} words\")\n",
    "        print(f\"Target length: {target_length} words\")\n",
    "        \n",
    "        current_text = text\n",
    "        iteration = 0\n",
    "        \n",
    "        while len(current_text.split()) > target_length and iteration < max_iterations:\n",
    "            iteration += 1\n",
    "            print(f\"\\n🔄 Iteration {iteration}:\")\n",
    "            \n",
    "            # If text is still very long, chunk it first\n",
    "            if len(current_text.split()) > 2000:\n",
    "                print(\"  📝 Chunking large text...\")\n",
    "                chunks = self.chunk_text(current_text, chunk_size=800, overlap=50)\n",
    "                print(f\"  Created {len(chunks)} chunks\")\n",
    "                \n",
    "                # Summarize each chunk\n",
    "                chunk_summaries = []\n",
    "                for i, chunk in enumerate(chunks):\n",
    "                    print(f\"  Processing chunk {i+1}/{len(chunks)}...\")\n",
    "                    chunk_summary = self.zero_shot_summarize(\n",
    "                        chunk, \n",
    "                        \"Summarize the key points from this text section:\"\n",
    "                    )\n",
    "                    chunk_summaries.append(chunk_summary)\n",
    "                \n",
    "                # Combine chunk summaries\n",
    "                current_text = ' '.join(chunk_summaries)\n",
    "                print(f\"  Combined chunks: {len(current_text.split())} words\")\n",
    "            \n",
    "            # Final summarization pass\n",
    "            if len(current_text.split()) > target_length:\n",
    "                print(\"  📋 Final summarization pass...\")\n",
    "                current_text = self.zero_shot_summarize(\n",
    "                    current_text,\n",
    "                    f\"Create a comprehensive summary of approximately {target_length} words:\"\n",
    "                )\n",
    "                print(f\"  Result: {len(current_text.split())} words\")\n",
    "        \n",
    "        print(f\"\\n✅ Final summary: {len(current_text.split())} words\")\n",
    "        return current_text\n",
    "    \n",
    "    def hierarchical_summarize(self, text, levels=[\"detailed\", \"medium\", \"brief\"]):\n",
    "        \"\"\"Create multiple summary levels\"\"\"\n",
    "        \n",
    "        level_configs = {\n",
    "            \"detailed\": {\"length\": 400, \"instruction\": \"Provide a detailed summary covering all major points:\"},\n",
    "            \"medium\": {\"length\": 200, \"instruction\": \"Create a balanced summary of key points:\"},\n",
    "            \"brief\": {\"length\": 100, \"instruction\": \"Write a concise summary of main ideas:\"},\n",
    "            \"executive\": {\"length\": 50, \"instruction\": \"Provide an executive summary in 2-3 sentences:\"}\n",
    "        }\n",
    "        \n",
    "        summaries = {}\n",
    "        \n",
    "        for level in levels:\n",
    "            if level in level_configs:\n",
    "                config = level_configs[level]\n",
    "                print(f\"\\n📊 Creating {level} summary (target: ~{config['length']} words)...\")\n",
    "                \n",
    "                summary = self.recursive_summarize(text, target_length=config['length'])\n",
    "                summaries[level] = summary\n",
    "                \n",
    "                print(f\"✅ {level.capitalize()} summary ({len(summary.split())} words):\")\n",
    "                print(summary[:200] + \"...\" if len(summary) > 200 else summary)\n",
    "        \n",
    "        return summaries\n",
    "\n",
    "# Initialize long document summarizer\n",
    "long_doc_summarizer = LongDocumentSummarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a344df68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test recursive summarization\n",
    "print(\"\\n🔄 Testing Recursive Summarization:\")\n",
    "recursive_result = long_doc_summarizer.recursive_summarize(long_document, target_length=150)\n",
    "\n",
    "# Test hierarchical summarization\n",
    "print(\"\\n📊 Testing Hierarchical Summarization:\")\n",
    "with open(\"articles/long_document.txt\", 'r', encoding='utf-8') as f:\n",
    "    long_document = f.read()\n",
    "    \n",
    "hierarchical_results = long_doc_summarizer.hierarchical_summarize(\n",
    "    long_document, \n",
    "    levels=[\"detailed\", \"medium\", \"brief\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade3dcaf",
   "metadata": {},
   "source": [
    "## **3.2 Multi-Document Summarization**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a314689",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiDocumentSummarizer(AbstractiveSummarizer):\n",
    "    \"\"\"Summarizer for handling multiple related documents\"\"\"\n",
    "    \n",
    "    def comparative_summarize(self, documents, document_labels=None):\n",
    "        \"\"\"Compare and contrast multiple documents\"\"\"\n",
    "        \n",
    "        if document_labels is None:\n",
    "            document_labels = [f\"Document {i+1}\" for i in range(len(documents))]\n",
    "        \n",
    "        # Create comparative prompt\n",
    "        comparative_prompt = \"\"\"\n",
    "        I need to analyze and compare multiple documents on related topics. \n",
    "        Please provide a comparative summary that:\n",
    "        1. Identifies common themes across documents\n",
    "        2. Highlights key differences in perspectives or findings\n",
    "        3. Synthesizes the most important information\n",
    "        4. Notes any contradictions or conflicting information\n",
    "        \n",
    "        Documents to compare:\n",
    "        \"\"\"\n",
    "        \n",
    "        for label, doc in zip(document_labels, documents):\n",
    "            comparative_prompt += f\"\\n\\n{label}:\\n{doc}\"\n",
    "        \n",
    "        comparative_prompt += \"\\n\\nComparative Summary:\"\n",
    "        \n",
    "        return self.generate(comparative_prompt, max_tokens=500)\n",
    "    \n",
    "    def synthesis_summarize(self, documents, focus_question=None):\n",
    "        \"\"\"Synthesize information from multiple sources\"\"\"\n",
    "        \n",
    "        if focus_question is None:\n",
    "            focus_question = \"What are the key insights when considering all sources together?\"\n",
    "        \n",
    "        synthesis_prompt = f\"\"\"\n",
    "        Synthesize information from the following sources to answer: {focus_question}\n",
    "        \n",
    "        Please create a synthesis that:\n",
    "        - Integrates information from all sources\n",
    "        - Identifies patterns and trends\n",
    "        - Resolves or notes conflicting information\n",
    "        - Provides a coherent unified perspective\n",
    "        \n",
    "        Sources:\n",
    "        \"\"\"\n",
    "        \n",
    "        for i, doc in enumerate(documents, 1):\n",
    "            synthesis_prompt += f\"\\n\\nSource {i}:\\n{doc}\"\n",
    "        \n",
    "        synthesis_prompt += f\"\\n\\nSynthesis addressing '{focus_question}':\"\n",
    "        \n",
    "        return self.generate(synthesis_prompt, max_tokens=500)\n",
    "\n",
    "# Initialize multi-document summarizer\n",
    "multi_doc_summarizer = MultiDocumentSummarizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e22cce",
   "metadata": {},
   "source": [
    "###  Multi-Document Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d7502c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_multi_document_summarization():\n",
    "    \"\"\"Test multi-document summarization with different perspectives\"\"\"\n",
    "    \n",
    "    # Three documents with different perspectives on remote work\n",
    "    documents = [\n",
    "        \"\"\"\n",
    "        Study A: Remote Work Productivity Analysis\n",
    "        A comprehensive study of 5,000 employees across 50 companies found that remote workers are 13% more productive than their office counterparts. The research, conducted over 18 months, measured productivity through completed tasks, project deadlines met, and output quality scores. Remote workers reported higher job satisfaction (8.2/10 vs 7.1/10) and better work-life balance. However, the study noted challenges in spontaneous collaboration and team building. Companies with strong digital infrastructure saw the highest productivity gains, while those with poor remote work policies experienced productivity declines.\n",
    "        \"\"\",\n",
    "        \"\"\"\n",
    "        Study B: Remote Work Challenges and Solutions\n",
    "        Research focusing on management perspectives reveals significant challenges in remote work implementation. Surveys of 1,200 managers indicate concerns about employee oversight (67%), team cohesion (58%), and maintaining company culture (52%). The study found that productivity varies significantly by role type, with creative and collaborative roles showing 8% decreased output while individual contributor roles improved by 12%. Communication frequency increased by 35% in remote teams, but decision-making speed decreased by 23%. Companies investing in management training for remote leadership saw better outcomes.\n",
    "        \"\"\",\n",
    "        \"\"\"\n",
    "        Study C: Economic Impact of Remote Work\n",
    "        Economic analysis of remote work trends shows substantial cost savings for both employers and employees. Companies report average savings of $11,000 per remote employee annually through reduced office space, utilities, and facility costs. Employees save an average of $4,000 yearly on commuting, work clothing, and meals. However, the analysis reveals increased spending on home office equipment and higher utility bills for workers. The real estate market has been significantly impacted, with commercial office space demand down 30% in major cities while residential markets in suburban areas have seen 15% price increases. The shift has created an estimated $1.2 trillion economic redistribution.\n",
    "        \"\"\"\n",
    "    ]\n",
    "    \n",
    "    labels = [\"Productivity Study\", \"Management Perspective\", \"Economic Analysis\"]\n",
    "    \n",
    "    print(\"📑 COMPARATIVE ANALYSIS:\")\n",
    "    print(\"=\" * 60)\n",
    "    comparative_result = multi_doc_summarizer.comparative_summarize(documents, labels)\n",
    "    print(comparative_result)\n",
    "    \n",
    "    print(\"\\n🔬 SYNTHESIS FOR POLICY MAKERS:\")\n",
    "    print(\"=\" * 60)\n",
    "    synthesis_result = multi_doc_summarizer.synthesis_summarize(\n",
    "        documents, \n",
    "        \"What policy recommendations emerge from considering all three studies?\"\n",
    "    )\n",
    "    print(synthesis_result)\n",
    "    \n",
    "    return comparative_result, synthesis_result\n",
    "\n",
    "comparative_analysis, synthesis_analysis = test_multi_document_summarization()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c69f26c",
   "metadata": {},
   "source": [
    "## **3.3 Multimodal Summarization**\n",
    "\n",
    "\n",
    "Multimodal summarization involves generating concise text that captures information from:\n",
    "- Text documents\n",
    "- Images\n",
    "- Tables and charts\n",
    "- Audio recordings\n",
    "- Video content\n",
    "\n",
    "## Approaches to Multimodal Summarization:\n",
    "\n",
    "1. **Pipeline Approach**: Process each modality separately, then combine\n",
    "2. **Unified Models**: Use multimodal models (like CLIP or GPT-4) that understand multiple modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e721c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing a multimodal summarizer for text + image data \n",
    "\n",
    "import requests\n",
    "import base64\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class MultimodalSummarizer:\n",
    "    \"\"\"Multimodal summarizer using Llama-4 Vision capabilities\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key=None):\n",
    "        \"\"\"Initialize the multimodal summarizer with an OPENROUTER API key\"\"\"\n",
    "        # Get API key from environment variable if not provided\n",
    "        self.api_key = api_key or os.environ.get(\"OPENROUTER_API_KEY\", \"\")\n",
    "        if not self.api_key:\n",
    "            print(\"Warning: No OPENROUTER API key provided. Please set your OPENROUTER_API_KEY.\")\n",
    "        \n",
    "        self.api_url = \"https://openrouter.ai/api/v1\"\n",
    "        self.model = \"meta-llama/llama-4-maverick:free\"\n",
    "        \n",
    "    def encode_image(self, image_path):\n",
    "        \"\"\"Encode an image to base64 for API submission\"\"\"\n",
    "        # Check if it's a URL or local path\n",
    "        if image_path.startswith(('http://', 'https://')):\n",
    "            response = requests.get(image_path)\n",
    "            image = Image.open(BytesIO(response.content))\n",
    "            buffered = BytesIO()\n",
    "            image.save(buffered, format=\"JPEG\")\n",
    "            return base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "        else:\n",
    "            with open(image_path, \"rb\") as image_file:\n",
    "                return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    \n",
    "    def create_payload(self, text, image_paths, max_tokens=500):\n",
    "        \"\"\"Create the API payload with text and images\"\"\"\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant that creates concise summaries from text and images.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": f\"Please create a comprehensive summary that combines information from the following text and images. Focus on integrating visual information with the text content.\\n\\nTEXT: {text}\"}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Add images to the content\n",
    "        for img_path in image_paths:\n",
    "            try:\n",
    "                base64_image = self.encode_image(img_path)\n",
    "                messages[1][\"content\"].append(\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                            \"detail\": \"high\"\n",
    "                        }\n",
    "                    }\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image {img_path}: {e}\")\n",
    "        \n",
    "        return {\n",
    "            \"model\": self.model,\n",
    "            \"messages\": messages,\n",
    "            \"max_tokens\": max_tokens\n",
    "        }\n",
    "    \n",
    "    def summarize_multimodal(self, text, image_paths, max_tokens=500):\n",
    "        \"\"\"Generate a summary from text and images using GPT-4\"\"\"\n",
    "        if not self.api_key:\n",
    "            return {\"error\": \"No API key provided. Please set your OPENROUTER_API_KEY.\"}\n",
    "        \n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\"\n",
    "        }\n",
    "        \n",
    "        payload = self.create_payload(text, image_paths, max_tokens)\n",
    "        \n",
    "        try:\n",
    "            print(\"Making API call to model...\")\n",
    "\n",
    "            response = requests.post(self.api_url, headers=headers, data=payload)\n",
    "            result = response.json()\n",
    "            \n",
    "            return {\n",
    "                'text_source': text,\n",
    "                'image_paths': image_paths,\n",
    "                'combined_summary': result\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e)}\n",
    "    \n",
    "    def display_images(self, image_paths):\n",
    "        \"\"\"Display the images used in the multimodal summary\"\"\"\n",
    "        num_images = len(image_paths)\n",
    "        \n",
    "        if num_images == 0:\n",
    "            return\n",
    "        \n",
    "        fig, axes = plt.subplots(1, num_images, figsize=(5*num_images, 5))\n",
    "        \n",
    "        if num_images == 1:\n",
    "            axes = [axes]  \n",
    "            \n",
    "        for i, img_path in enumerate(image_paths):\n",
    "            try:\n",
    "                # Handle both URLs and local paths\n",
    "                if img_path.startswith(('http://', 'https://')):\n",
    "                    response = requests.get(img_path)\n",
    "                    img = Image.open(BytesIO(response.content))\n",
    "                else:\n",
    "                    img = Image.open(img_path)\n",
    "                \n",
    "                axes[i].imshow(img)\n",
    "                axes[i].set_title(f\"Image {i+1}\")\n",
    "                axes[i].axis('off')\n",
    "            except Exception as e:\n",
    "                axes[i].text(0.5, 0.5, f\"Error loading image: {e}\", \n",
    "                             ha='center', va='center', transform=axes[i].transAxes)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('multimodal_input.png')\n",
    "        plt.close()\n",
    "        \n",
    "        from IPython.display import Image\n",
    "        return Image('multimodal_input.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3103a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = [\n",
    "    # \"images/image1.jpg\",\n",
    "    # \"images/image2.jpg\",\n",
    "    # \"images/image3.png\"\n",
    "]\n",
    "\n",
    "multimodal_summarizer = MultimodalSummarizer()\n",
    "\n",
    "# Generate a multimodal summary\n",
    "multimodal_result = multimodal_summarizer.summarize_multimodal(\n",
    "    #article,\n",
    "    image_paths,\n",
    "    max_tokens=300\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b6a0ad",
   "metadata": {},
   "source": [
    "### Practical Exercise: Building Your Custom Summarization System\n",
    "\n",
    "Now it's your turn to build a complete summarization system by combining techniques we've explored.\n",
    "\n",
    "\n",
    "## Project Ideas:\n",
    "1. **News Summarizer Bot**: Create a system that retrieves and summarizes news articles on specific topics\n",
    "2. **Meeting Minutes Generator**: Transcribe and summarize meeting audio recordings\n",
    "3. **Research Paper Summarizer**: Generate summaries of academic papers with focus on methodology and results\n",
    "4. **Medical Conversation Summarizer**: Summarize doctor-patient conversations, creating dual summaries (technical for doctors, simplified for patients)\n",
    "5. **EHR Summarizer**: Create a system that generates longitudinal patient summaries from fragmented electronic health records, retrieving and synthesizing information across multiple visits, lab results, and clinical notes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5483f7a1",
   "metadata": {},
   "source": [
    "### Code and Libraries:\n",
    "- [Transformers Documentation](https://huggingface.co/docs/transformers/index)\n",
    "- [Text Generation Parameters](https://huggingface.co/blog/mlabonne/decoding-strategies)\n",
    "\n",
    "\n",
    "## Useful Resources:\n",
    "\n",
    "### Datasets:\n",
    "- [CNN/Daily Mail Dataset](https://huggingface.co/datasets/cnn_dailymail)\n",
    "- [XSum Dataset](https://huggingface.co/datasets/xsum)\n",
    "- [Multi-News](https://huggingface.co/datasets/multi_news)\n",
    "- [BBC News Summary Dataset](https://www.kaggle.com/datasets/pariza/bbc-news-summary)\n",
    "\n",
    "### Evaluation Tools:\n",
    "- [ROUGE Implementation in Python](https://github.com/google-research/google-research/tree/master/rouge)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bbbbc2",
   "metadata": {},
   "source": [
    "Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1794a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribing audio files\n",
    "import whisper\n",
    "\n",
    "def transcribe_meeting(audio_file):\n",
    "    model = whisper.load_model(\"base\")\n",
    "    result = model.transcribe(audio_file)\n",
    "    return result[\"text\"]\n",
    "\n",
    "# download audio from youtube\n",
    "import yt_dlp\n",
    "# pip install yt-dlp\n",
    "def download_audio_yt_dlp(url: str, output_path: str = \"downloads\") -> str:\n",
    "    \"\"\"\n",
    "    Downloads audio from a YouTube video using yt-dlp.\n",
    "\n",
    "    Args:\n",
    "        url (str): YouTube video URL.\n",
    "        output_path (str): Directory to save the audio.\n",
    "\n",
    "    Returns:\n",
    "        str: Path to the downloaded file.\n",
    "    \"\"\"\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'outtmpl': f'{output_path}/%(title)s.%(ext)s',\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'mp3',\n",
    "            'preferredquality': '192',\n",
    "        }],\n",
    "        'quiet': False,\n",
    "    }\n",
    "\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        info = ydl.extract_info(url, download=True)\n",
    "        return f\"{output_path}/{info['title']}.mp3\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9f76b4",
   "metadata": {},
   "source": [
    "# **Facilitator(s) Details**\n",
    "\n",
    "**Facilitator(s):**\n",
    "\n",
    "*   Name: Nana Sam Yeboah                       \n",
    "*   Email: nanayeb34@gmail.com\n",
    "*   LinkedIn: [Nana Sam Yeboah](https://www.linkedin.com/in/nana-sam-yeboah-0b664484)\n",
    "\n",
    "# \n",
    "\n",
    "*   Name: Audrey Eyram Agbeve\n",
    "*   Email: audreyagbeve02@gmail.com\n",
    "*   LinkedIn: [Audrey (Eyram) Agbeve](https://www.linkedin.com/in/audreyagbeve02/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f827823",
   "metadata": {},
   "source": [
    "### Please rate this Tutorial\n",
    "\n",
    "<img src=\"images/Day1_feedback.png\" height=500 width=500  >"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
