{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "d_HCdEmNbf4P",
        "tugUfmZtcRSq"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Introduction to PyTorch and Libraries for Deep Learning**\n",
        "\n",
        "By *Joshua Otis*"
      ],
      "metadata": {
        "id": "X-YERvzuPgeq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Pre-shared Content for Advanced PyTorch Tutorial**\n",
        "\n",
        "**Title:** *Preparation for \"Introduction to PyTorch and Libraries for Deep Learning\"*\n",
        "\n",
        "\n",
        "### 1. **Prerequisites Checklist**\n",
        "\n",
        "Participants should be comfortable with:\n",
        "\n",
        "* Python programming (functions, classes, NumPy)\n",
        "* Basic concepts in machine learning (e.g., regression, classification)\n",
        "* Jupyter notebooks or a Python IDE\n",
        "\n",
        "**NOTE**:  This tutorial session would be run entirely in Google Colab\n",
        "\n",
        "Participants can complete a quick Python refresher if needed:\n",
        "\n",
        "* [Python for Data Science Handbook (Chapters 1–3)](https://jakevdp.github.io/PythonDataScienceHandbook/)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### 2. **Environment Setup Instructions**\n",
        "\n",
        "Install the following libraries in Google Colab before the session:\n",
        "\n",
        "#### Install via `pip`:\n",
        "\n",
        "```python\n",
        "# Check if running in Colab\n",
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"Running in Google Colab. Installing required packages...\")\n",
        "    !pip install torch torchvision lightning matplotlib scikit-learn pandas --quiet\n",
        "else:\n",
        "    print(\"You're not in Colab. Please ensure all dependencies are installed.\")\n",
        "```\n",
        "\n",
        "Link to the official PyTorch install guide (auto-configures commands):\n",
        "\n",
        "[https://pytorch.org/get-started/locally/](https://pytorch.org/get-started/locally/)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "###3. **Pre-reading / Learning Materials**\n",
        "\n",
        "#### I. **What is Deep Learning?**\n",
        "\n",
        "Brief introduction:\n",
        "\n",
        "* [Deep Learning Overview - MIT](https://introtodeeplearning.com)\n",
        "* [3Blue1Brown – What is a Neural Network?](https://www.youtube.com/watch?v=aircAruvnKk)\n",
        "* [Neural Networks and Deep Learning by Michael A. Nielsen](http://neuralnetworksanddeeplearning.com/)\n",
        "\n",
        "#### II. **Intro to PyTorch**\n",
        "\n",
        "* [Official PyTorch 60-Minute Blitz](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)\n",
        "* [PyTorch for Deep Learning (FreeCodeCamp, first 45 mins)](https://www.youtube.com/watch?v=GIsg-ZUy0MY)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### 4. **Libraries to Familiarize With**\n",
        "\n",
        "You can familiarize yourself with the following PyTorch libraries by taking a look at these:\n",
        "\n",
        "* `torchvision` – For loading datasets (like CIFAR-10, MNIST)\n",
        "* `torch.nn` – For building neural network architectures\n",
        "* `torch.optim` – For optimization algorithms like SGD, Adam\n",
        "* `sklearn` – For evaluation metrics (accuracy, confusion matrix, etc.)\n",
        "\n",
        "\n",
        "Link to some cheat sheets or docs:\n",
        "\n",
        "* [PyTorch Documentation](https://pytorch.org/docs/stable/index.html)\n",
        "* [Torchvision Documentation](https://pytorch.org/vision/stable/index.html)\n",
        "* [Torchnn Documentation](https://docs.pytorch.org/docs/stable/nn.html)\n",
        "* [Torchlightning Documentation](https://lightning.ai/docs/pytorch/stable/)\n",
        "\n",
        "###5. **Pre-work Notebook or Exercise**\n",
        "\n",
        "**Objective:** Warm-up with PyTorch tensors and basic NN structure.\n",
        "\n",
        "Look at some simple notebook or script that includes:\n",
        "\n",
        "* Creating and manipulating tensors\n",
        "* Building a simple linear model\n",
        "* Using `autograd` and `.backward()`\n",
        "\n",
        "You can create this or adapt it from:\n",
        "\n",
        "* [PyTorch Tutorials GitHub](https://github.com/pytorch/tutorials/tree/main/beginner_source/basics)"
      ],
      "metadata": {
        "id": "JUmIySBe4oTs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Session Objectives**\n",
        "\n",
        "\n",
        "##**PART A**\n",
        "\n",
        "##I. Introduction\n",
        "* Review foundational deep learning principles to contextualize PyTorch's role in model development.\n",
        "\n",
        "* Understand the significance of PyTorch in modern deep learning research and production pipelines.\n",
        "\n",
        "* Clarify the objectives of the session and align expectations with advanced learning outcomes.\n",
        "\n",
        "##II. Advanced PyTorch Concepts\n",
        "* Perform complex tensor operations and transformations using PyTorch’s tensor API for high-performance computation.\n",
        "\n",
        "* Utilize PyTorch’s autograd system to implement custom optimization workflows with automatic differentiation.\n",
        "\n",
        "* Design and build reusable and composable neural network architectures using torch.nn.Module.\n",
        "\n",
        "* Develop custom datasets and implement efficient data pipelines using DataLoader.\n",
        "\n",
        "##**PART B**\n",
        "\n",
        "##III. Deep Learning Libraries and Tools\n",
        "* Apply torchvision for image/video processing tasks and leverage pre-trained models for transfer learning.\n",
        "\n",
        "* Use PyTorch Lightning to simplify training loops.\n",
        "\n",
        "* Explore additional PyTorch libraries like TorchText, TorchAudio, Ignite and Catalyst to enhance training workflows and performance monitoring.\n",
        "\n",
        "##IV. Sample Dataset for PyTorch\n",
        "* Use of PyTorch to run the FashionMNIST dataset.\n",
        "\n",
        "##**PART C**\n",
        "\n",
        "##V. Challenge\n",
        "* Create a task for participants to check their level of understanding.\n",
        "\n",
        "\n",
        "##VI. Conclusion and Next Steps\n",
        "* Summarize the session’s key takeaways, reinforcing practical skills and theoretical insights.\n",
        "\n",
        "* Identify reliable resources for continuous learning (e.g., research papers, tutorials, code repositories).\n",
        "\n",
        "* Develop confidence and curiosity to independently explore and implement advanced deep learning models using PyTorch.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FeykQw6F7VRz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PART A"
      ],
      "metadata": {
        "id": "d_HCdEmNbf4P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Why Deep Learning?**\n"
      ],
      "metadata": {
        "id": "U4E-atcYx2xg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Real-World Problems Solved by Deep Learning**\n",
        "\n",
        "* **Computer Vision**:\n",
        "\n",
        "  * Object detection, facial recognition, autonomous driving\n",
        "  * E.g., Tesla Autopilot, Google Photos tagging\n",
        "* **Natural Language Processing (NLP)**:\n",
        "\n",
        "  * Translation, chatbots, sentiment analysis\n",
        "  * E.g., Google Translate, Siri, ChatGPT\n",
        "* **Games & Reinforcement Learning**:\n",
        "\n",
        "  * Mastering Go, Chess, and StarCraft\n",
        "  * E.g., AlphaGo by DeepMind\n",
        "* **Healthcare & Bioinformatics**:\n",
        "\n",
        "  * Cancer detection from scans, protein folding\n",
        "  * E.g., DeepMind’s AlphaFold\n"
      ],
      "metadata": {
        "id": "1QTvb1PTPrtq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**PyTorch**"
      ],
      "metadata": {
        "id": "4oO_DQC2Shfa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch is an open source machine learning (ML) framework based on the Python programming language and the Torch library.\n"
      ],
      "metadata": {
        "id": "RnMjIyZ6THhW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **Why PyTorch?**\n",
        "\n",
        "* **Flexible & Dynamic**:\n",
        "\n",
        "  * Eager execution model—debug and test like regular Python\n",
        "* **Pythonic & Intuitive**:\n",
        "\n",
        "  * Seamlessly integrates with Python’s ecosystem\n",
        "* **Researcher-Friendly**:\n",
        "\n",
        "  * Widely adopted in academic papers and ML research\n",
        "* **Strong Ecosystem**:\n",
        "\n",
        "  * Libraries like TorchVision, TorchText, PyTorch Lightning\n",
        "* **Production-Ready**:\n",
        "\n",
        "  * TorchScript, ONNX support, and deployment tools"
      ],
      "metadata": {
        "id": "QzwVqeTJSvU2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Over the course of this tutorial we are going to\n",
        "\n",
        "#### **1. Understand Core PyTorch Concepts**\n",
        "\n",
        "* Learn how PyTorch works under the hood: tensors, autograd, and modules\n",
        "* Explore model building, training loops, and optimization\n",
        "* Understand how PyTorch differs from other frameworks (e.g., TensorFlow)\n",
        "\n",
        "\n",
        "#### **2. Explore Key Libraries for Deep Learning**\n",
        "\n",
        "* **TorchVision** – tools for image data: transforms, datasets, pre-trained models\n",
        "* **PyTorch Lightning** - a lightweight wrapper for PyTorch that simplifies training loops, logging, and scaling.\n",
        "* Speak briefly on ***other libraries*** like\n",
        "  * TorchAudio\n",
        "  * TorchText\n",
        "  * PyTorch Ignite\n",
        "  * Catalyst\n",
        "\n",
        "#### **3. Apply Knowledge in a Hands-On Challenge**\n",
        "\n",
        "* Build and train a PyTorch model on toy image or data\n",
        "* Use real deep learning workflows: data preprocessing, model creation, training, evaluation\n",
        "* Gain practical experience integrating PyTorch libraries\n"
      ],
      "metadata": {
        "id": "o0uW7CICUpkQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **PyTorch**\n",
        "\n",
        "PyTorch is a powerful and intuitive deep learning framework that combines:\n",
        "\n",
        "* NumPy-like tensors\n",
        "\n",
        "* Automatic gradient computation\n",
        "\n",
        "* Modular network design\n",
        "\n",
        "* Easy GPU support\n",
        "\n"
      ],
      "metadata": {
        "id": "aaPsrPL1Ynr1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We begin by looking at the PyTorch library and some of the things it contains then we explore the concepts"
      ],
      "metadata": {
        "id": "WYeg2yoLedrR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "wlsjclrvFFpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir(torch.stack)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "r3u5FkGwFQFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(torch.arange)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "izEhXda6FwGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Core PyTorch Concepts**"
      ],
      "metadata": {
        "id": "OgC-_FCSZUff"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **PyTorch Tensors: Creation and Operations**\n",
        "* Tensors are multidimensional arrays, similar to NumPy arrays, but with GPU support.\n",
        "\n",
        "* Support broadcasting, indexing, slicing, reshaping (view, reshape), and efficient in-place operations.\n",
        "\n",
        "* Advanced operations: einsum, matrix multiplication (matmul, bmm, mm), and tensor arithmetic.\n",
        "\n",
        "For documentation on PyTorch tensors, learn more at\n",
        "\n",
        "https://pytorch.org/docs/stable/tensors.html"
      ],
      "metadata": {
        "id": "pxNSmOUP4Pcq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Examples\n",
        "Here we look at an example of where tensors are used in tensor multplication, indexing, slicing and reshaping\n"
      ],
      "metadata": {
        "id": "qYdbIDHlDTeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "a = torch.tensor(3.) #Scalar\n",
        "b = torch.tensor([1., 2, 3, 4]) #Vector\n",
        "c = torch.tensor([[5., 6],\n",
        "                  [7, 8],\n",
        "                  [9, 10]]) #Matrix\n",
        "a.dtype\n",
        "a.shape"
      ],
      "metadata": {
        "id": "KAZmXIOdfLra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##EXAMPLE\n",
        "\n",
        "import torch\n",
        "\n",
        "a = torch.randn(3,4)\n",
        "b = torch.randn(2,4,5)\n",
        "a\n",
        "b"
      ],
      "metadata": {
        "id": "vOj7L_4HOiA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### A simple 3D tensor\n",
        "\n",
        "tensor_3d = torch.tensor([\n",
        "    [[ 1,  2,  3,  4],\n",
        "     [ 5,  6,  7,  8],\n",
        "     [ 9, 10, 11, 12]],\n",
        "\n",
        "    [[13, 14, 15, 16],\n",
        "     [17, 18, 19, 20],\n",
        "     [21, 22, 23, 24]]\n",
        "])\n",
        "\n",
        "print(\"Original 3D Tensor (2x3x4):\\n\", tensor_3d)\n"
      ],
      "metadata": {
        "id": "DftCcVVLROE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Indexing in 3D\n",
        "\n",
        "# Get element at batch 1, row 2, column 3\n",
        "element = tensor_3d[1, 2, 3]\n",
        "print(\"Indexed Element [1, 2, 3]:\", element)  # Output: 24"
      ],
      "metadata": {
        "id": "Sud4IoUvRVDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Slicing in 3D\n",
        "\n",
        "# Get all rows and columns of the first batch\n",
        "slice_1 = tensor_3d[0, :, :]\n",
        "print(\"Slice of first batch (0):\\n\", slice_1)\n",
        "\n",
        "# Get only the first two columns across all batches and rows\n",
        "slice_2 = tensor_3d[:, :, :2]\n",
        "print(\"First two columns of every row in every batch:\\n\", slice_2)\n",
        "\n",
        "# Get the middle row (row 1) of each batch\n",
        "slice_3 = tensor_3d[:, 1, :]\n",
        "print(\"Middle row of each batch:\\n\", slice_3)\n"
      ],
      "metadata": {
        "id": "J3zuK42iRipo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Reshaping in 3D\n",
        "\n",
        "# Reshape entire tensor (2x3x4) into (3x2x4)\n",
        "reshaped = tensor_3d.permute(1, 0, 2)\n",
        "print(\"Reshaped Tensor (3x2x4):\\n\", reshaped)\n",
        "\n",
        "# Flatten each batch (from 3x4 to 12)\n",
        "flattened_batches = tensor_3d.view(2, -1)\n",
        "print(\"Each batch flattened:\\n\", flattened_batches)\n"
      ],
      "metadata": {
        "id": "4Zjdmv2pTBKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##EXAMPLE\n",
        "\n",
        "#Using Standard Matrix Multiplication (2D only)\n",
        "\n",
        "# a: shape (3, 4)\n",
        "# b: shape (4, 5)\n",
        "a = torch.randn(3, 4)\n",
        "b = torch.randn(4, 5)\n",
        "\n",
        "result = torch.mm(a, b)\n",
        "print(result.shape)  # (3, 5)"
      ],
      "metadata": {
        "id": "UbPGhNE43h5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#EXAMPLE\n",
        "\n",
        "#Using Batch Matrix Multiplication (3D only with first dimension as batch size)\n",
        "\n",
        "# a: shape (10, 3, 4) — batch of 10 matrices (3x4)\n",
        "# b: shape (10, 4, 2) — batch of 10 matrices (4x2)\n",
        "a = torch.randn(10, 3, 4)\n",
        "b = torch.randn(10, 4, 2)\n",
        "\n",
        "result = torch.bmm(a, b)\n",
        "print(result.shape)  # (10, 3, 2)"
      ],
      "metadata": {
        "id": "1V2UmJgj4skS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##EXAMPLE\n",
        "\n",
        "#Using Matrix Multiplication (3D)\n",
        "\n",
        "# a: shape (2, 3, 4)\n",
        "# b: shape (2, 4, 5) — compatible for batch matrix multiplication\n",
        "a = torch.randn(2, 3, 4)\n",
        "b = torch.randn(2, 4, 5)\n",
        "\n",
        "# Will perform batched matrix multiplication across batch dimension\n",
        "result = torch.matmul(a, b)\n",
        "print(result.shape)  # (2, 3, 5)"
      ],
      "metadata": {
        "id": "EouBQHg5um__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##EXAMPLE\n",
        "\n",
        "#Using  Matrix Multiplication with Broadcasting\n",
        "\n",
        "# a: shape (2, 3, 4) — batch of 2 matrices, each 3×4\n",
        "a = torch.randn(2, 3, 4)\n",
        "\n",
        "# b: shape (4, 5) — a single matrix 4×5\n",
        "b = torch.randn(4, 5)\n",
        "\n",
        "# Broadcasted: b is broadcast across the batch dimension of a\n",
        "result = torch.matmul(a, b)\n",
        "print(result.shape)  # (2, 3, 5)"
      ],
      "metadata": {
        "id": "zd73UyY94Pe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Similarly the EXAMPLE above can be broadcasted this way\n",
        "\n",
        "a = torch.randn(3, 4)     # shape (3, 4)\n",
        "b = torch.randn(2, 4, 5)  # shape (2, 4, 5)\n",
        "\n",
        "result = torch.matmul(a, b)  # a is broadcast to (2, 3, 4)\n",
        "print(result.shape)  # (2, 3, 5)"
      ],
      "metadata": {
        "id": "dbZk9PBo5v4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##EXAMPLE\n",
        "\n",
        "#Creating an L-norm\n",
        "\n",
        "# Create a 1D tensor (vector)\n",
        "v = torch.tensor([3.0, 4.0])\n",
        "\n",
        "# Compute the L2 norm (Euclidean norm, p=2)\n",
        "l2_norm = torch.norm(v, p=2)\n",
        "\n",
        "print(f\"Vector: {v}\")\n",
        "print(f\"L2 Norm: {l2_norm}\")  # Should output 5.0 (√(3² + 4²))\n"
      ],
      "metadata": {
        "id": "XC2KtEsHPs8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##EXAMPLE\n",
        "\n",
        "#Creating a Frobenius norm\n",
        "\n",
        "# 2D tensor (matrix)\n",
        "A = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
        "\n",
        "# Frobenius norm (default for matrices with p=2)\n",
        "fro_norm = torch.norm(A, p='fro')\n",
        "\n",
        "print(f\"Matrix:\\n{A}\")\n",
        "print(f\"Frobenius Norm: {fro_norm}\")  # √(1² + 2² + 3² + 4²) = √30 ≈ 5.477\n"
      ],
      "metadata": {
        "id": "kjYBf2PUQYky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "x = np.array([[1,2],[3,4]])\n",
        "x"
      ],
      "metadata": {
        "id": "A8OLrvRUg5P2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert numpy array to to a torch tensor\n",
        "y = torch.from_numpy(x)\n",
        "y"
      ],
      "metadata": {
        "id": "L7Ie7WgrhOdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.dtype, y.dtype"
      ],
      "metadata": {
        "id": "szd3SPTrhg3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = y.numpy()\n",
        "z"
      ],
      "metadata": {
        "id": "YgH9Cr99hpMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Example: Image Tensor Transformations**\n",
        "Let us say you have an image tensor of shape **[batch_size, height, width, channels]**, and you want to feed it into a CNN which expects **[batch_size, channels, height, width]**."
      ],
      "metadata": {
        "id": "-QpfCXNcGlzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Assume your image data is in a NumPy array called 'image_np'\n",
        "# Replace this with your actual image data loading\n",
        "import numpy as np\n",
        "image_np = np.random.randint(0, 255, size=(10, 32, 32, 3), dtype=np.uint8)\n",
        "\n",
        "# Convert the NumPy array to a PyTorch tensor\n",
        "image = torch.from_numpy(image_np)\n",
        "\n",
        "# Now you can permute the dimensions\n",
        "image = image.permute(0, 3, 1, 2)  # Rearranges dimensions\n",
        "\n",
        "print(image.shape)"
      ],
      "metadata": {
        "id": "vqEtvJ9wHZm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a sample tensor for 'x'\n",
        "x = torch.randn(4, 5, 6)  # Example tensor with shape (4, 5, 6)\n",
        "\n",
        "\n",
        "x = x.view(x.size(0), -1)  # Flatten all but batch dimension\n",
        "\n",
        "print(x.shape)"
      ],
      "metadata": {
        "id": "i7VvjTe0H4uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **PyTorch Autograd**\n",
        "Automatic Differentiation\n",
        "* PyTorch dynamically builds a computation graph as operations occur.\n",
        "\n",
        "* Uses `requires_grad=True` to track operations for automatic gradient calculation.\n",
        "\n",
        "* Backpropagation via `.backward()` triggers gradient computation.\n",
        "\n",
        "Gradient Computation & Optimization\n",
        "* Access gradients via `.grad` attributes on tensors.\n",
        "\n",
        "Common workflow:\n",
        "\n",
        "`loss.backward()`\n",
        "\n",
        "`optimizer.step()`\n",
        "\n",
        "`optimizer.zero_grad()`\n",
        "\n",
        "* Integrates with `torch.optim` for efficient parameter updates.\n",
        "\n",
        "For documentation on PyTorch automatic differentiation, learn more at\n",
        "\n",
        "https://docs.pytorch.org/docs/stable/autograd.html"
      ],
      "metadata": {
        "id": "WWIYPl7c-gKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "y = x ** 3 + 2 * x\n",
        "y.backward()  #compute derivatives\n",
        "print(x.grad)  # dy/dx = 3x² + 2 = 3(2²) + 2 = 14"
      ],
      "metadata": {
        "id": "ia6DexiVIK5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A more detailed example using the gradient descent and optimization"
      ],
      "metadata": {
        "id": "opAHzGbgJBDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# Example data: y = 2x + 3\n",
        "x = torch.tensor([[1.0], [2.0], [3.0]])\n",
        "y_true = torch.tensor([[5.0], [7.0], [9.0]])\n",
        "\n",
        "# Initialize weights and bias\n",
        "weight = torch.randn(1, 1, requires_grad=True)\n",
        "bias = torch.randn(1, requires_grad=True)\n",
        "\n",
        "# Define a simple linear model\n",
        "def model(x):\n",
        "    return x @ weight + bias  # matrix multiply + bias\n",
        "\n",
        "# Define mean squared error loss\n",
        "def mse_loss(y_pred, y_true):\n",
        "    return ((y_pred - y_true) ** 2).mean()\n",
        "\n",
        "# Use SGD optimizer to update weight and bias\n",
        "optimizer = torch.optim.SGD([weight, bias], lr=0.01)\n",
        "\n",
        "# Forward pass\n",
        "y_pred = model(x)\n",
        "loss = mse_loss(y_pred, y_true)\n",
        "\n",
        "print(\"Loss before backward:\", loss.item())\n",
        "\n",
        "# Backward pass\n",
        "loss.backward()\n",
        "\n",
        "# Update parameters\n",
        "optimizer.step()\n",
        "\n",
        "# Zero gradients\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# Check updated weights and bias\n",
        "print(\"Updated weight:\", weight.data)\n",
        "print(\"Updated bias:\", bias.data)\n"
      ],
      "metadata": {
        "id": "ckVj217yJAdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the code above, we look at a linear regression where we use weights and biases to predict the system using an optimization technique called the gradient descent.\n",
        "\n",
        "Mathematically this can be expressed as\n",
        "$$y = XW^T + b$$\n"
      ],
      "metadata": {
        "id": "LlBHyoNnjWv_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **PyTorch Modules**\n",
        "\n",
        "Building Custom Modules\n",
        "* Subclass `nn.Module` to define custom models.\n",
        "\n",
        "* Implement `__init__()` for layers and `forward()` for logic.\n",
        "\n",
        "Example\n",
        "\n",
        "```python\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self): ...\n",
        "    def forward(self, x): ...\n",
        "    \n",
        "```\n",
        "Module Composition & Reuse\n",
        "* Nest modules inside others using `nn.Sequential`, containers, or custom hierarchies.\n",
        "\n",
        "* Enables model reuse, better organization, and cleaner code.\n",
        "\n",
        "For documentation on PyTorch Modules, learn more at\n",
        "\n",
        "https://docs.pytorch.org/docs/stable/notes/modules.html"
      ],
      "metadata": {
        "id": "y45cYPBxARwO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####A simple custom model\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "import torch.nn as nn\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc = nn.Linear(10, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "```"
      ],
      "metadata": {
        "id": "Sw-IxrNU9Gxi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####A more complex model\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.layer1 = nn.Linear(10, 20)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.layer2 = nn.Linear(20, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.relu(x)\n",
        "        return self.layer2(x)\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_features):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Linear(in_features, in_features),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features, in_features)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.block(x)  # Skip connection\n",
        "\n",
        "class ResNetMini(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.input = nn.Linear(64, 64)\n",
        "        self.resblock1 = ResidualBlock(64)\n",
        "        self.resblock2 = ResidualBlock(64)\n",
        "        self.output = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input(x)\n",
        "        x = self.resblock1(x)\n",
        "        x = self.resblock2(x)\n",
        "        return self.output(x)\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(10, 20),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20, 1)\n",
        ")\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "2kyYnZnQ9jix"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **PyTorch Data Loaders**\n",
        "Custom Data Loading & Preprocessing\n",
        "* Implement custom `Dataset` by subclassing `torch.utils.data.Dataset`.\n",
        "\n",
        "* Use `DataLoader` to batch, shuffle, and load data with multiprocessing.\n",
        "\n",
        "For documentation on PyTorch Data Loaders and Datasets, learn more at\n",
        "\n",
        "https://docs.pytorch.org/tutorials/beginner/basics/data_tutorial.html"
      ],
      "metadata": {
        "id": "uSjwNUqBBLmW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "dataset = TensorDataset(torch.rand(100, 10), torch.rand(100, 1))\n",
        "loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "```"
      ],
      "metadata": {
        "id": "eaO30-V7-E5I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we proceed, let us combine our knowledge so far to create a simple Neural Network Module"
      ],
      "metadata": {
        "id": "IXi0YODh2NqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch Neural Network Module\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# 1. Create a Toy Dataset\n",
        "X = torch.rand(100, 10)  # 100 samples, 10 features\n",
        "y = torch.rand(100, 1)   # 100 target values (e.g., regression)\n",
        "\n",
        "dataset = TensorDataset(X, y)\n",
        "loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# 2. Define a Simple Neural Network using nn.Module\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(10, 32)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(32, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n",
        "\n",
        "model = SimpleNet()\n",
        "\n",
        "# 3. Define Loss and Optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# 4. Train the Model\n",
        "for epoch in range(5):  # 5 epochs for demo\n",
        "    for batch_X, batch_y in loader:\n",
        "        pred = model(batch_X)               # Forward pass\n",
        "        loss = criterion(pred, batch_y)     # Compute loss\n",
        "\n",
        "        optimizer.zero_grad()               # Zero gradients\n",
        "        loss.backward()                     # Backpropagation\n",
        "        optimizer.step()                    # Update weights\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "\n",
        "print(\"Training complete. You can now evaluate or save the model.\")\n"
      ],
      "metadata": {
        "id": "uKKkCztJoCrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PART B"
      ],
      "metadata": {
        "id": "tugUfmZtcRSq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this second session, we would explore\n",
        "\n",
        "* Deep learning libraries associated with PyTorch\n",
        "* A dataset with PyTorch\n",
        "* Building a model"
      ],
      "metadata": {
        "id": "gMticOabNhQV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Key Deep Learning Libraries**"
      ],
      "metadata": {
        "id": "sm4ExjGe2fUS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Torchvision**\n",
        "Image and Video Processing\n",
        "* Built-in transforms for cropping, resizing, normalizing, augmenting images.\n",
        "\n",
        "* Datasets like MNIST, CIFAR-10, ImageNet, COCO readily available.\n",
        "\n",
        "Pre-trained Models & Transfer Learning\n",
        "* Access pretrained CNNs (ResNet, VGG, EfficientNet, etc.).\n",
        "\n",
        "* Easily fine-tune on custom datasets:\n",
        "```python\n",
        "model = models.resnet50(pretrained=True)\n",
        "model.fc = nn.Linear(...custom_classes)\n",
        "```\n",
        "\n",
        "For documentation on Torchvision, learn more at\n",
        "\n",
        "https://docs.pytorch.org/vision/stable/index.html"
      ],
      "metadata": {
        "id": "oE5O-rQh2wQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Load the MNIST dataset\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "# Create a DataLoader for batching\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Example of a transformation\n",
        "resize_transform = transforms.Resize((32, 32))"
      ],
      "metadata": {
        "id": "O5vZHVPWx9Ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**PyTorch Lightning**\n",
        "\n",
        "PyTorch Lightning is a lightweight wrapper around PyTorch designed to:\n",
        "\n",
        "* Decouple model code from engineering code (e.g., training loops, GPU management)\n",
        "\n",
        "* Simplify complex training pipelines\n",
        "\n",
        "* Make your research more readable, scalable, and reproducible\n",
        "\n",
        "It follows the philosophy:\n",
        "\n",
        "\"Focus on the science, not the boilerplate.\"\n",
        "\n",
        "For documentation on PyTorch Lightning, learn more at\n",
        "\n",
        "https://lightning.ai/docs/pytorch/stable/\n"
      ],
      "metadata": {
        "id": "DrdSXwtgcMQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Get the data\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "train_data = datasets.MNIST(root='.', train=True, download=True, transform=transform)\n",
        "test_data = datasets.MNIST(root='.', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64)\n",
        "\n",
        "# Step 2: Create a model\n",
        "class MNISTModel(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(28 * 28, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = nn.functional.cross_entropy(logits, y)\n",
        "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
        "        self.log(\"train_loss\", loss)\n",
        "        self.log(\"train_acc\", acc)\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = nn.functional.cross_entropy(logits, y)\n",
        "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
        "        self.log(\"test_loss\", loss)\n",
        "        self.log(\"test_acc\", acc)\n",
        "        return {\"x\": x, \"y\": y, \"preds\": logits.argmax(dim=1)}\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
        "\n",
        "# Step 3: Train the dataset\n",
        "logger = TensorBoardLogger(\"tb_logs\", name=\"mnist\")\n",
        "model = MNISTModel()\n",
        "trainer = pl.Trainer(max_epochs=5, logger=logger, enable_checkpointing=False)\n",
        "trainer.fit(model, train_loader)\n",
        "\n",
        "# Step 4: Test the dataset\n",
        "test_results = trainer.test(model, test_loader)\n",
        "\n",
        "# Step 5: Evaluate the model\n",
        "model.eval()\n",
        "sample_batch = next(iter(test_loader))\n",
        "images, labels = sample_batch\n",
        "with torch.no_grad():\n",
        "    preds = model(images).argmax(dim=1)\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    plt.imshow(images[i].squeeze(), cmap='gray')\n",
        "    plt.title(f\"Pred: {preds[i].item()}\\nTrue: {labels[i].item()}\")\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_STnefl89txF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Advanced Deep Learning Libraries and Tools**"
      ],
      "metadata": {
        "id": "U1cN50gZTKuZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Torchtext**\n",
        "Text Processing and Preprocessing\n",
        "* Tokenization, vocabulary building, padding, and batching built-in.\n",
        "\n",
        "* Supports datasets like IMDB, AG News, and more.\n",
        "\n",
        "Word Embeddings and Language Models\n",
        "* Pre-trained embeddings (GloVe, FastText) for initializing models.\n",
        "\n",
        "* Interface with Transformers for fine-tuning NLP tasks.\n",
        "\n",
        "For documentation on TorchText, learn more at\n",
        "\n",
        "https://docs.pytorch.org/text/stable/index.html\n"
      ],
      "metadata": {
        "id": "tPAsse3y4R_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**TorchAudio**\n",
        "\n",
        "Torchaudio is a domain-specific library built to integrate audio processing capabilities directly into the PyTorch ecosystem.\n",
        "It provides:\n",
        "\n",
        "* Easy-to-use dataset loaders for popular audio datasets\n",
        "\n",
        "* Efficient audio transformations and feature extraction (e.g., Mel spectrograms)\n",
        "\n",
        "* Tools for building and training speech models, including support for pre-trained models\n",
        "\n",
        "It allows you to go from raw waveform → features → deep model → predictions in one pipeline.\n",
        "\n",
        "For documentation on TorchAudio, learn more at\n",
        "\n",
        "https://docs.pytorch.org/audio/stable/index.html"
      ],
      "metadata": {
        "id": "UKKmJu6JSq0E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**PyTorch Ignite**\n",
        "\n",
        "PyTorch Ignite is a high-level library built on PyTorch for:\n",
        "\n",
        "* Rapidly developing research workflows\n",
        "\n",
        "* Managing training and evaluation loops\n",
        "\n",
        "* Simplifying event-driven logging, checkpointing, and metrics\n",
        "\n",
        "It provides flexible, yet powerful abstractions for both beginners and experienced ML engineers.\n",
        "\n",
        "For documentation on PyTorch Ignite, learn more at\n",
        "\n",
        "https://docs.pytorch.org/ignite/index.html"
      ],
      "metadata": {
        "id": "9kleYUm8cMNC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Catalyst**\n",
        "\n",
        "Catalyst is a deep learning framework for fast prototyping and reproducible experiments. It is built on top of PyTorch and Ignite, but offers a higher-level interface.\n",
        "\n",
        "Catalyst is especially suited for:\n",
        "\n",
        "* ML research\n",
        "\n",
        "* Kaggle competitions\n",
        "\n",
        "* Industrial production pipelines\n",
        "\n",
        "For more on Catalyst, see\n",
        "\n",
        "https://catalyst-team.com/"
      ],
      "metadata": {
        "id": "O_Y6mBwCcL_o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dataset Overview – FashionMNIST**"
      ],
      "metadata": {
        "id": "RrilwHEl3i1k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Why FashionMNIST?**\n",
        "\n",
        "* Designed as a **drop-in replacement for MNIST**\n",
        "* Slightly more complex: better for benchmarking real-world models\n",
        "* Small, grayscale images (28×28), ideal for beginners\n",
        "\n",
        "\n",
        "#### **Categories of Fashion Items**\n",
        "\n",
        "FashionMNIST includes **10 classes**:\n",
        "\n",
        "1. T-shirt/top\n",
        "2. Trouser\n",
        "3. Pullover\n",
        "4. Dress\n",
        "5. Coat\n",
        "6. Sandal\n",
        "7. Shirt\n",
        "8. Sneaker\n",
        "9. Bag\n",
        "10. Ankle boot\n",
        "\n",
        "\n",
        "\n",
        "#### **Data Shape and Labels**\n",
        "\n",
        "* **Images**: `28 x 28` grayscale (1 channel)\n",
        "* **Label type**: integer (0 to 9)\n",
        "* **Train/Test split**:\n",
        "\n",
        "  * **60,000** training images\n",
        "  * **10,000** test images\n"
      ],
      "metadata": {
        "id": "yk6RGD7wUaj7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Problem Statement**\n",
        "\n",
        "####  **Goal**\n",
        "\n",
        "* Build a model that can **accurately classify** clothing images from the **FashionMNIST** dataset.\n",
        "\n",
        "\n",
        "#### **Task**\n",
        "\n",
        "* Train a **neural network classifier** using PyTorch\n",
        "* Input: `28x28` grayscale image\n",
        "* Output: One of **10 fashion item classes**\n",
        "\n",
        "\n",
        "#### **Evaluation Metric**\n",
        "\n",
        "* **Accuracy**: Percentage of correctly predicted labels over total samples\n"
      ],
      "metadata": {
        "id": "W4RKh-OPV_a8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hands-On with PyTorch: FashionMNIST Classifier\n",
        "\n",
        "# Step 1: Import Libraries\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# Step 2: Load the FashionMNIST Dataset\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "train_data = torchvision.datasets.FashionMNIST(root='data', train=True, download=True, transform=transform)\n",
        "test_data = torchvision.datasets.FashionMNIST(root='data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
        "\n",
        "# Step 3: Visualize Sample Images\n",
        "classes = train_data.classes\n",
        "def show_images(images, labels):\n",
        "    fig, ax = plt.subplots(1, 6, figsize=(12, 4))\n",
        "    for i in range(6):\n",
        "        ax[i].imshow(images[i][0], cmap='gray')\n",
        "        ax[i].set_title(classes[labels[i]])\n",
        "        ax[i].axis('off')\n",
        "\n",
        "images, labels = next(iter(train_loader))\n",
        "show_images(images, labels)\n",
        "\n",
        "# Step 4: Define a Neural Network\n",
        "class FashionClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(28*28, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 10)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        return self.model(x)\n",
        "\n",
        "model = FashionClassifier().to(device)\n",
        "\n",
        "# Step 5: Train the Model\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            print(f\"loss: {loss.item():>7f}  [{batch * len(X):>5d}/{size:>5d}]\")\n",
        "\n",
        "for epoch in range(5):\n",
        "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "    train(train_loader, model, loss_fn, optimizer)\n",
        "print(\"Training done!\")\n",
        "\n",
        "# Step 6: Evaluate the Model\n",
        "def test(dataloader, model):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "            total += y.size(0)\n",
        "    accuracy = correct / total\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "test(test_loader, model)"
      ],
      "metadata": {
        "id": "p_yHwGtjT2r5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Step-by-Step – Build Your First Model**"
      ],
      "metadata": {
        "id": "Kf5J49NY4HCJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Step-by-Step – Build Your First Model\n",
        "\n",
        "#### **1. Define the Network**\n",
        "\n",
        "* Use `nn.Module` to create a **simple feedforward neural network**\n",
        "* Input: Flattened `28x28` $\\rightarrow$ Linear layers $\\rightarrow$ ReLU $\\rightarrow$ Output (10 classes)\n",
        "* Tip: Start with one hidden layer to keep it simple\n",
        "\n",
        "```python\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "```\n",
        "\n",
        "#### **2. Choose Loss and Optimizer**\n",
        "\n",
        "* Loss: `nn.CrossEntropyLoss()` – for multi-class classification\n",
        "* Optimizer: `torch.optim.Adam()` or `SGD` for training\n",
        "\n",
        "```python\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "```\n",
        "\n",
        "\n",
        "#### **3. Training Loop**\n",
        "\n",
        "* Iterate through batches\n",
        "* Perform **forward pass**, **loss computation**, **backpropagation**, and **parameter update**\n",
        "\n",
        "```python\n",
        "for images, labels in train_loader:\n",
        "    outputs = model(images.view(-1, 28*28))\n",
        "    loss = criterion(outputs, labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "```\n"
      ],
      "metadata": {
        "id": "ir7Nx537Y7_8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So for our model we have"
      ],
      "metadata": {
        "id": "ywrcgAppl1JJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build Your First PyTorch Model – FashionMNIST\n",
        "#In this notebook, you will\n",
        "#Define a simple neural network\n",
        "#Train it on FashionMNIST\n",
        "#Track loss and accuracy\n",
        "\n",
        "# Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Data loading\n",
        "## 1. Load the FashionMNIST Dataset\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Define model\n",
        "## 2. Define the Neural Network\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)  # Flatten\n",
        "        x = self.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n",
        "\n",
        "model = Net()\n",
        "\n",
        "# Loss and optimizer\n",
        "## 3. Set Loss Function and Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "## 4. Train the Model\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# Evaluation\n",
        "## 5. Evaluate on Test Set\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Test Accuracy: {100 * correct / total:.2f}%')\n"
      ],
      "metadata": {
        "id": "5T2x2mqKXRa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PART C"
      ],
      "metadata": {
        "id": "mZKfet8fDdjB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this last session, we will look at\n",
        "* An improved version of the FashionMNIST dataset model\n",
        "* A challenge\n",
        "* Best practices for PyTorch\n",
        "* Next steps"
      ],
      "metadata": {
        "id": "Y5E6CDMxDpn_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an improved version of the FashionMNIST model with added features and visualizations\n",
        "\n",
        "#Improved FashionMNIST Model – PyTorch\n",
        "#This notebook extends the basic model with:\n",
        "#Additional hidden layers\n",
        "#Dropout for regularization\n",
        "#Training/validation loss visualization\n",
        "#Sample predictions\n",
        "\n",
        "# Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# Data loading and train/val split\n",
        "## 1. Load and Split the Dataset\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "train_full = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "train_size = int(0.8 * len(train_full))\n",
        "val_size = len(train_full) - train_size\n",
        "train_dataset, val_dataset = random_split(train_full, [train_size, val_size])\n",
        "\n",
        "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Improved model\n",
        "## 2. Define an Improved Neural Network\n",
        "class ImprovedNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImprovedNet, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(28*28, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        return self.model(x)\n",
        "\n",
        "model = ImprovedNet()\n",
        "\n",
        "# Loss and optimizer\n",
        "## 3. Set Loss and Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training with validation tracking\n",
        "## 4. Train the Model with Validation\n",
        "train_losses, val_losses = [], []\n",
        "epochs = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    train_losses.append(running_loss / len(train_loader))\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "    val_losses.append(val_loss / len(val_loader))\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}\")\n",
        "\n",
        "# Plotting training vs validation loss\n",
        "## 5. Visualize Training and Validation Loss\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.show()\n",
        "\n",
        "# Evaluation\n",
        "## 6. Evaluate on Test Set\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Test Accuracy: {100 * correct / total:.2f}%')\n",
        "\n",
        "# Sample predictions\n",
        "## 7. Show Sample Predictions\n",
        "classes = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat','Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "def imshow(img):\n",
        "    plt.imshow(img.squeeze(), cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "dataiter = iter(test_loader)\n",
        "images, labels = next(dataiter)\n",
        "outputs = model(images)\n",
        "_, preds = torch.max(outputs, 1)\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "for i in range(6):\n",
        "    plt.subplot(2, 6, i + 1)\n",
        "    imshow(images[i])\n",
        "    plt.title(f\"Pred: {classes[preds[i]]}\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XUOtMLJZnlNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Challenge!**"
      ],
      "metadata": {
        "id": "6iZRd86Y4W42"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Your Task: Improve the Model Accuracy**\n",
        "\n",
        "You have trained a basic neural network — now make it better!\n",
        "\n",
        "#### **Things You Can Try:**\n",
        "\n",
        "* **Change Model Architecture:**\n",
        "  Add more layers, try different activation functions, or switch to CNNs.\n",
        "\n",
        "* **Apply Data Augmentation:**\n",
        "  Use `transforms` (e.g., `RandomHorizontalFlip`, `RandomCrop`) to improve generalization.\n",
        "\n",
        "* **Tune Hyperparameters:**\n",
        "  Adjust:\n",
        "\n",
        "  * Learning rate\n",
        "  * Batch size\n",
        "  * Optimizer (try SGD, Adam, etc.)\n",
        "\n",
        "* **Add Regularization Techniques:**\n",
        "\n",
        "  * **Dropout**\n",
        "  * **Batch Normalization**"
      ],
      "metadata": {
        "id": "vkr3Z_s3qm4v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These lines of code are for the facilitators explanation\n",
        "```python\n",
        "#Challenge: Improve Your FashionMNIST Model\n",
        "#In this notebook, you will experiment with different ways to improve model performance on the FashionMNIST dataset.\n",
        "# Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "## 1. Data Loading and Augmentation\n",
        "# TODO: Add your own data augmentation transforms here\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.RandomHorizontalFlip(),\n",
        "    # transforms.RandomRotation(10),\n",
        "])\n",
        "\n",
        "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "## 2. Define Your Custom Model\n",
        "class CustomNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomNet, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(28*28, 128),\n",
        "            nn.ReLU(),\n",
        "            # TODO: Add dropout, batch norm, more layers\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        return self.model(x)\n",
        "\n",
        "model = CustomNet()\n",
        "\n",
        "\n",
        "## 3. Loss and Optimizer (Tune Me!)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  #TODO: Try different optimizers (SGD) or learning rates\n",
        "\n",
        "\n",
        "## 4. Training Loop\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "\n",
        "## 5. Evaluate Your Model\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Test Accuracy: {100 * correct / total:.2f}%')\n",
        "\n",
        "# Final challenge prompt\n",
        "## Challenge Tips\n",
        "#Add hidden layers\n",
        "#Use dropout or batch norm\n",
        "#Tune learning rate, optimizer\n",
        "#Try data augmentation\n",
        "#Run, modify, experiment!\n",
        "\n",
        "```\n",
        "\n",
        "The next lines of code with the blanks are for the challenge to be handled by the participants during the session.\n",
        "\n",
        "The blanks are for the particpants to try out different options and then it would be discussed which options work best and why?"
      ],
      "metadata": {
        "id": "cNmLBx3rcFLG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to recall essential information taught during the session to replicate the lines of code we have learnt during the tutorial session and check the levels of understanding of participants.\n",
        "\n",
        "\n",
        "---\n",
        "Fill in the blanks"
      ],
      "metadata": {
        "id": "i1UuWxYhAS-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Challenge: Improve Your FashionMNIST Model\n",
        "#In this notebook, you will experiment with different ways to improve model performance on the FashionMNIST dataset.\n",
        "\n",
        "# Imports\n",
        "import torch\n",
        "import ... as nn\n",
        "import ... as optim\n",
        "from ... import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import ... as plt\n",
        "\n",
        "\n",
        "## 1. Data Loading and Augmentation\n",
        "# TODO: Add your own data augmentation transforms here\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.RandomHorizontalFlip(),\n",
        "    # transforms.RandomRotation(10),\n",
        "])\n",
        "\n",
        "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size= ..., shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size= ..., shuffle=False)\n",
        "\n",
        "## 2. Define Your Custom Model\n",
        "class CustomNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomNet, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(28*28, 128),\n",
        "            nn.ReLU(),\n",
        "            # TODO: Add dropout, batch norm, more layers\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        return self.model(x)\n",
        "\n",
        "model = CustomNet()\n",
        "\n",
        "\n",
        "## 3. Loss and Optimizer (Tune Me!)\n",
        "criterion = ...\n",
        "optimizer = ...(model.parameters(), lr=...)\n",
        "\n",
        "\n",
        "## 4. Training Loop\n",
        "epochs = ...\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        outputs = model(...)\n",
        "        loss = criterion(outputs, ...)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "\n",
        "## 5. Evaluate Your Model\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(...)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == ...).sum().item()\n",
        "\n",
        "print(f'Test Accuracy: {100 * correct / total:.2f}%')"
      ],
      "metadata": {
        "id": "Rz4HlPdtdgrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Best Practices in PyTorch**"
      ],
      "metadata": {
        "id": "QPkejXkr5aMi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1. Use `Dataset` + `DataLoader`**\n",
        "\n",
        "* Wrap your data using `torch.utils.data.Dataset`\n",
        "* Efficiently load it using `DataLoader` (supports batching, shuffling, parallelism)\n",
        "* Enables easy scaling to large datasets\n",
        "\n",
        "```python\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "```\n",
        "\n",
        "\n",
        "#### **2. Track Loss and Accuracy**\n",
        "\n",
        "* Log training/validation **loss** and **accuracy** at every epoch\n",
        "* Helps diagnose underfitting/overfitting and guide improvements\n",
        "* Use tools like:\n",
        "\n",
        "  * Simple print statements\n",
        "  * Matplotlib plots\n",
        "  * TensorBoard (`torch.utils.tensorboard`)\n",
        "\n",
        "\n",
        "#### **3. Save & Load Models**\n",
        "\n",
        "* Always save your trained model checkpoints:\n",
        "\n",
        "```python\n",
        "torch.save(model.state_dict(), 'model.pth')\n",
        "```\n",
        "\n",
        "* Load them later for inference or resuming training:\n",
        "\n",
        "```python\n",
        "model.load_state_dict(torch.load('model.pth'))\n",
        "model.eval()\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "###**Tip:** Structure your training scripts for reproducibility and clarity."
      ],
      "metadata": {
        "id": "cp8fwM2t4mqM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Resources for Further Learning**"
      ],
      "metadata": {
        "id": "do-LP5Xs6U_e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1. PyTorch Official Tutorials**\n",
        "\n",
        "* Step-by-step guides for beginners to experts\n",
        "  \n",
        "  [pytorch.org/tutorials](https://pytorch.org/tutorials/)\n",
        "\n",
        "\n",
        "#### **2. Fast.ai Deep Learning Course**\n",
        "\n",
        "* Practical, top-down learning with PyTorch\n",
        "  \n",
        "  [course.fast.ai](https://course.fast.ai)\n",
        "\n",
        "#### **3. Papers with Code**\n",
        "\n",
        "* Find state-of-the-art research with implementations\n",
        "  \n",
        "  [paperswithcode.com](https://paperswithcode.com)\n",
        "\n",
        "\n",
        "#### **4. Hugging Face Model Hub**\n",
        "\n",
        "* Access thousands of pretrained models for NLP, vision, and audio\n",
        "  \n",
        "  [huggingface.co/models](https://huggingface.co/models)\n"
      ],
      "metadata": {
        "id": "pcw3eykV4wLl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hx1YzGRhsv3y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}